{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\"\"\"\n",
    "今までlouvain法だと思っていたものはnewman法だった，newman法で改めて実装してみて精度を比較\n",
    "newman法の方が精度が高い，従ってnewman法を採用\n",
    "\"\"\"\n",
    "import networkx as nx\n",
    "import csv\n",
    "import community\n",
    "import collections\n",
    "from igraph import *\n",
    "import pickle\n",
    "import numpy as np\n",
    "from openopt import QP\n",
    "\n",
    "\n",
    "# csvファイルの読み込み\n",
    "def readcsv(path):\n",
    "    f = open(path, \"rb\")\n",
    "    dataReader = csv.reader(f)\n",
    "    arr = [row for row in dataReader]\n",
    "    return arr\n",
    "\n",
    "def writecsv(arr, path):\n",
    "    f = open(path, \"ab\")\n",
    "    dataWriter = csv.writer(f)\n",
    "    dataWriter.writerows(arr)\n",
    "    f.close()\n",
    "\n",
    "def readdump(path):\n",
    "    f = open(path, \"r\")\n",
    "    arr = pickle.load(f)\n",
    "    f.close()\n",
    "    return arr\n",
    "\n",
    "# 有向エッジリストを入力して、重み付き無向ネットワークを出力する\n",
    "def cal_edgelist_to_network(list_edge):\n",
    "    # 有向エッジリストを無向エッジリストに変換する\n",
    "    list_edge = [tuple(sorted(row)) for row in list_edge]\n",
    "    # ノードリスト\n",
    "    list_vertices = list(set([word for row in list_edge for word in row]))\n",
    "    # エッジリストとそのweightを作成\n",
    "    tuple_edge, tuple_weight = zip(*collections.Counter(list_edge).items())\n",
    "    return {\"vertex\": list_vertices, \"edge\": list(tuple_edge), \"weight\": list(tuple_weight)}\n",
    "\n",
    "# クラスタリング済みのネットワークを元にサブグラフのリストを作成\n",
    "# vertexには全てのvertexを代入する（PageRankを計算するため）\n",
    "def cal_cluster_to_network(dict_network):\n",
    "    if dict_network.has_key(\"cluster\") == False:\n",
    "        print \"クラスタリングができていません\"\n",
    "    \n",
    "    # クラスタごとにwordをまとめる\n",
    "    dict_cluster = collections.defaultdict(list)\n",
    "    for word, cluster in zip(dict_network[\"vertex\"], dict_network[\"cluster\"]):\n",
    "        dict_cluster[cluster].append(word)\n",
    "\n",
    "    # リストに変換\n",
    "    list_cluster_vertex = [row[1] for row in dict_cluster.items()]\n",
    "    \n",
    "    # 同様にエッジとウェイトのリストも作成する\n",
    "    list_cluster_edge = []\n",
    "    list_cluster_weight = []\n",
    "    for cluster_vertex in list_cluster_vertex:\n",
    "        list_cluster_edge_one = []\n",
    "        list_cluster_weight_one = []\n",
    "        # エッジリストの中に、一つでもノードが含まれていれば、そのクラスのノードに含める\n",
    "        for row, weight in zip(dict_network[\"edge\"], dict_network[\"weight\"]):\n",
    "            # and と or を切り替えることによって性能の比較\n",
    "            if row[0] in cluster_vertex or row[1] in cluster_vertex:\n",
    "                list_cluster_edge_one.append(row)\n",
    "                list_cluster_weight_one.append(weight)\n",
    "        list_cluster_edge.append(list_cluster_edge_one)\n",
    "        list_cluster_weight.append(list_cluster_weight_one)\n",
    "    \n",
    "    # まとめる\n",
    "    list_dict_network = [{\"vertex\": dict_network[\"vertex\"],\n",
    "                          \"edge\": cluster_edge,\n",
    "                          \"weight\": cluster_weight}\n",
    "                         for cluster_edge, cluster_weight\n",
    "                         in zip(list_cluster_edge, list_cluster_weight)]\n",
    "    \n",
    "    return list_dict_network\n",
    "\n",
    "# f_measureを計算する\n",
    "def cal_f_measure(list_predict_measure):\n",
    "    # 生成したクラスタ内のカウント\n",
    "    dict_predict_cluster = collections.defaultdict(list)\n",
    "    for row in list_predict_measure:\n",
    "        dict_predict_cluster[row[0]].append(row[1])\n",
    "        \n",
    "    # もとあるクラス内のカウント\n",
    "    dict_measure_cluster = collections.defaultdict(list)\n",
    "    for row in list_predict_measure:\n",
    "        dict_measure_cluster[row[1]].append(row[0])\n",
    "    \n",
    "    # local_purityの計算\n",
    "    list_purity = []\n",
    "    for row in dict_predict_cluster.items():\n",
    "        major_class = sorted(collections.Counter(row[1]).items(), key=lambda x: x[1], reverse=True)[0][1]\n",
    "        class_num = len(row[1])\n",
    "        list_purity.append([major_class, class_num])\n",
    "    purity = float(np.sum(zip(*list_purity)[0])) / np.sum(zip(*list_purity)[1])\n",
    "    print \"Purity: \", purity\n",
    "    \n",
    "    # inverse_purityの計算\n",
    "    list_inverse_purity = []\n",
    "    for row in dict_measure_cluster.items():\n",
    "        major_class = sorted(collections.Counter(row[1]).items(), key=lambda x: x[1], reverse=True)[0][1]\n",
    "        class_num = len(row[1])\n",
    "        list_inverse_purity.append([major_class, class_num])\n",
    "    inverse_purity = float(np.sum(zip(*list_inverse_purity)[0])) / np.sum(zip(*list_inverse_purity)[1])\n",
    "    print \"Inverse Purity: \", inverse_purity\n",
    "    \n",
    "    print \"F-value: \", 2 / (1 / purity + 1 / inverse_purity)\n",
    "    \n",
    "# 凸２次計画問題を解いてp(topic)を求めるための関数\n",
    "def cal_prob_topic(dict_network_master, list_dict_network_sub):\n",
    "    prob_master = np.array([row[1] for row in sorted(zip(dict_network_master[\"vertex\"], dict_network_master[\"page_rank\"]), key=lambda x: x[0])])\n",
    "    \n",
    "    for i, dict_network_sub in enumerate(list_dict_network_sub):\n",
    "        if i == 0:\n",
    "            prob_sub = np.array([row[1] for row in sorted(zip(dict_network_sub[\"vertex\"], dict_network_sub[\"page_rank\"]), key=lambda x: x[0])])\n",
    "        else:\n",
    "            list_tmp = np.array([row[1] for row in sorted(zip(dict_network_sub[\"vertex\"], dict_network_sub[\"page_rank\"]), key=lambda x: x[0])])\n",
    "            prob_sub = np.vstack((prob_sub, list_tmp))\n",
    "    \n",
    "    H = 2 * prob_sub.dot(prob_sub.T)\n",
    "    f = -2 * prob_master.dot(prob_sub.T)\n",
    "    Aeq = np.ones(len(list_dict_network_sub))\n",
    "    beq = 1\n",
    "    lb = np.zeros(len(list_dict_network_sub))\n",
    "    \n",
    "    p = QP(H, f, Aeq=Aeq, beq=beq, lb=lb)\n",
    "    r = p.solve(\"cvxopt_qp\")\n",
    "    k_opt = r.xf\n",
    "    return k_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "クラスタ数:  9\n",
      "\n",
      "------------------------- OpenOpt 0.5625 -------------------------\n",
      "problem: unnamed   type: QP\n",
      "solver: cvxopt_qp\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.9346e-03 -1.0040e+00  1e+00  4e-17  3e+00\n",
      " 1: -2.9356e-03 -1.3951e-02  1e-02  1e-16  4e-02\n",
      " 2: -2.9918e-03 -3.7429e-03  8e-04  8e-17  2e-03\n",
      " 3: -3.0690e-03 -3.1413e-03  7e-05  1e-16  2e-18\n",
      " 4: -3.0714e-03 -3.0731e-03  2e-06  8e-17  9e-19\n",
      " 5: -3.0714e-03 -3.0714e-03  2e-08  1e-16  2e-18\n",
      " 6: -3.0714e-03 -3.0714e-03  2e-10  9e-17  3e-18\n",
      "Optimal solution found.\n",
      "istop: 1000 (optimal)\n",
      "Solver:   Time Elapsed = 0.07 \tCPU Time Elapsed = 0.01\n",
      "objFuncValue: -0.0030714159 (feasible, MaxResidual = 0)\n"
     ]
    }
   ],
   "source": [
    "# エッジリストの読み込み\n",
    "list_edge = readcsv(\"./files/rakuten_corpus/rakuten_corpus_edgelist.csv\")\n",
    "# 元のネットワークを作成する（無向）\n",
    "dict_network_master = cal_edgelist_to_network(list_edge)\n",
    "# networkxとigraphの両方でネットワークを作成\n",
    "g_master = Graph()\n",
    "g_master.add_vertices(dict_network_master[\"vertex\"])\n",
    "g_master.add_edges(dict_network_master[\"edge\"])\n",
    "\n",
    "G=nx.Graph()\n",
    "for edge_row, weight in zip(dict_network_master[\"edge\"], dict_network_master[\"weight\"]):\n",
    "    G.add_edge(edge_row[0], edge_row[1], weight=weight)\n",
    "# networkxのlouvain法により，分割\n",
    "partition = community.best_partition(G)\n",
    "dict_network_master[\"cluster\"] = [partition[vertex] for vertex in dict_network_master[\"vertex\"]]\n",
    "# 元のネットワークのpagerankを求める\n",
    "dict_network_master[\"page_rank\"] = g_master.pagerank(directed=False, weights=dict_network_master[\"weight\"])\n",
    "# クラスタ結果をもとにサブグラフのリストを作成\n",
    "list_dict_network_sub = cal_cluster_to_network(dict_network_master)\n",
    "# サブクラスタごとに中心性の計算\n",
    "for i, dict_network_sub in enumerate(list_dict_network_sub):\n",
    "    g_sub = Graph()\n",
    "    g_sub.add_vertices(dict_network_sub[\"vertex\"])\n",
    "    g_sub.add_edges(dict_network_sub[\"edge\"])\n",
    "    list_dict_network_sub[i][\"center_bet\"] = g_sub.betweenness(directed=False, weights=dict_network_sub[\"weight\"])\n",
    "    list_dict_network_sub[i][\"center_eigen\"] = g_sub.eigenvector_centrality(directed=False, weights=dict_network_sub[\"weight\"])\n",
    "    list_dict_network_sub[i][\"page_rank\"] = g_sub.pagerank(directed=False, weights=dict_network_sub[\"weight\"])\n",
    "print \"クラスタ数: \", len(list_dict_network_sub)\n",
    "\n",
    "# トピックごとにwordを入力したらp(word|topic)が出るような辞書を作成\n",
    "list_dict_prob = []\n",
    "for i in range(len(list_dict_network_sub)):\n",
    "    list_word_page = sorted(zip(list_dict_network_sub[i][\"vertex\"], list_dict_network_sub[i][\"page_rank\"]), key=lambda x: x[1], reverse=True)\n",
    "    list_dict_prob.append({row[0]: row[1] for row in list_word_page})\n",
    "    \n",
    "# 凸２次計画問題を解いて、p(topic)を求める\n",
    "list_prob_topic = cal_prob_topic(dict_network_master, list_dict_network_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "風呂 0.0314473746693\n",
      "広い 0.0252853166713\n",
      "残念 0.0237885974666\n",
      "快適 0.0178795977401\n",
      "大浴場 0.0138648614682\n",
      "綺麗 0.0133903534676\n",
      "子供 0.0123478492823\n",
      "狭い 0.0114234408302\n",
      "無い 0.0107109056212\n",
      "きれい 0.010519395602\n"
     ]
    }
   ],
   "source": [
    "num = 0\n",
    "list_tmp = sorted(list_dict_prob[num].items(), key=lambda x: x[1], reverse=True)\n",
    "for i in range(10):\n",
    "    print list_tmp[i][0], list_tmp[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_dict_words = dict_network_master[\"vertex\"]\n",
    "list_sep_words = readdump(\"./files/rakuten_corpus/annotation/hiro_tetsuo_sep.dump\")\n",
    "list_sep_words_rev = []\n",
    "for row in list_sep_words:\n",
    "    list_tmp = []\n",
    "    for word in row[1]:\n",
    "        if word in list_dict_words:\n",
    "            list_tmp.append(word)\n",
    "    if row[2] != 6:\n",
    "        list_sep_words_rev.append([list_tmp, row[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "エラーデータ数:  0\n"
     ]
    }
   ],
   "source": [
    "# 確率が最大になるクラスを予想する\n",
    "# 実質ラベルがintじゃない場合は、エラーとして、記録しない\n",
    "list_predict_measure = []\n",
    "list_words_rev = []\n",
    "error_count = 0\n",
    "for row in list_sep_words_rev:\n",
    "    try:\n",
    "        class_tmp = 0\n",
    "        prob_tmp = 0\n",
    "        predict_class = []\n",
    "        for num, dict_prob in enumerate(list_dict_prob):\n",
    "            prob_tmp_tmp = 1\n",
    "            for word in row[0]:\n",
    "                prob_tmp_tmp *= float(dict_prob[word])\n",
    "            prob_tmp_tmp *= list_prob_topic[num]\n",
    "            if prob_tmp_tmp > prob_tmp:\n",
    "                class_tmp = num\n",
    "                prob_tmp = prob_tmp_tmp\n",
    "        list_predict_measure.append([class_tmp, row[1]])\n",
    "    except:\n",
    "        error_count += 1\n",
    "print \"エラーデータ数: \", error_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity:  0.584022038567\n",
      "Inverse Purity:  0.60927456382\n",
      "F-value:  0.596381104409\n"
     ]
    }
   ],
   "source": [
    "cal_f_measure(list_predict_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
