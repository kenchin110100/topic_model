{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\"\"\"\n",
    "頻度により除去語を指定しないコーパスを使う\n",
    "1文ずつ形態素解析したものと、口コミごとに形態素解析したものの2種類を作成\n",
    "有向グラフ用のエッジリストも作成\n",
    "\"\"\"\n",
    "import MeCab\n",
    "import csv\n",
    "import collections\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "def parsing(sentence):\n",
    "    mecab = MeCab.Tagger(\"-d /usr/local/lib/mecab/dic/mecab-ipadic-neologd\")\n",
    "    res = mecab.parseToNode(sentence)\n",
    "    list_words = []\n",
    "    while res:\n",
    "        features = res.feature.split(\",\")\n",
    "        if (features[0] == \"名詞\" and features[1] in [\"一般\", \"固有名詞\", \"サ変接続\", \"形容動詞語幹\"]) or features[0] == \"形容詞\":\n",
    "            if features[6] == \"*\":\n",
    "                list_words.append(res.surface)\n",
    "            else:\n",
    "                list_words.append(features[6])\n",
    "        res = res.next\n",
    "    return list_words\n",
    "\n",
    "# csvファイルの読み込み\n",
    "def readcsv(path):\n",
    "    f = open(path, \"rb\")\n",
    "    dataReader = csv.reader(f)\n",
    "    arr = [row for row in dataReader]\n",
    "    return arr\n",
    "\n",
    "def readtsv(path):\n",
    "    f = open(path, \"rb\")\n",
    "    dataReader = csv.reader(f, delimiter='\\t')\n",
    "    arr = [row for row in dataReader]\n",
    "    return arr\n",
    "\n",
    "def writecsv(arr, path):\n",
    "    f = open(path, \"ab\")\n",
    "    dataWriter = csv.writer(f)\n",
    "    dataWriter.writerows(arr)\n",
    "    f.close()\n",
    "\n",
    "def writedump(arr, path):\n",
    "    f = open(path, \"w\")\n",
    "    pickle.dump(arr, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### コーパス作成\n",
    "1. 同じユーザーの口コミを1文にまとめる\n",
    "2. ユーザーごとに形態素解析したリストを作成\n",
    "3. 高頻度、低頻度語を削除するために、除去語リストを作成する\n",
    "4. 除去"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19401\n",
      "3780\n"
     ]
    }
   ],
   "source": [
    "list_sentences = readtsv(\"./files/rakuten_corpus/annotation01_tsukuba_corpus_20140930.tsv\")\n",
    "# 同じユーザーの口コミを1文にまとめる\n",
    "list_sentences_rev = []\n",
    "sentence_tmp = \"\"\n",
    "for row in list_sentences:\n",
    "    if row[5] != \"\":\n",
    "        sentence_tmp += row[5]\n",
    "    else:\n",
    "        list_sentences_rev.append(sentence_tmp)\n",
    "        sentence_tmp = \"\"\n",
    "list_sentences_rev.append(sentence_tmp)\n",
    "\n",
    "\n",
    "# 形態素解析したリストを作成\n",
    "list_words = [parsing(row) for row in list_sentences_rev]\n",
    "\n",
    "\n",
    "\n",
    "# 各単語の頻度を数え上げる\n",
    "list_words_collection = []\n",
    "for row in list_words:\n",
    "    list_words_collection.extend(row)\n",
    "\n",
    "# 除去語を省く前の語彙数と語数\n",
    "print len(list_words_collection)\n",
    "print len(set(list_words_collection))\n",
    "    \n",
    "list_words_collection = collections.Counter(list_words_collection).items()\n",
    "\n",
    "# 除去語リストを作成\n",
    "list_words_remove = []\n",
    "for row in list_words_collection:\n",
    "    if row[1] < 3 or row[1] > 300:\n",
    "        list_words_remove.append(row[0])\n",
    "\n",
    "# 除去語リスト内の単語を削除\n",
    "list_words_rev = []\n",
    "for row in list_words:\n",
    "    list_words_tmp = []\n",
    "    for word in row:\n",
    "        if word in list_words_remove:\n",
    "            pass\n",
    "        else:\n",
    "            list_words_tmp.append(word)\n",
    "    list_words_rev.append(list_words_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### コーパスから有向エッジリストを作成し、保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# エッジリストを作成\n",
    "list_edgelist = []\n",
    "for row in list_words:\n",
    "    for j in range(len(row) - 1):\n",
    "        list_edgelist.append([row[j], row[j+1]])\n",
    "\n",
    "# 作成したエッジリストを保存\n",
    "writecsv(list_edgelist, \"./files/rakuten_corpus_edgelist_full.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UM用のコーパスを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_sentences = readtsv(\"./files/rakuten_corpus/annotation01_tsukuba_corpus_20140930.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 空白行を削除\n",
    "list_sentences_rev = []\n",
    "for row in list_sentences:\n",
    "    if row[5] != '':\n",
    "        list_sentences_rev.append(row[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_words = [parsing(row) for row in list_sentences_rev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writecsv(list_words, \"./files/rakuten_corpus/rakuten_corpus_full_for_UM.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 共起グラフでのエッジリスト作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_sentences = readtsv(\"./files/rakuten_corpus/annotation01_tsukuba_corpus_20140930.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 空白行を削除\n",
    "list_sentences_rev = []\n",
    "for row in list_sentences:\n",
    "    if row[5] != '':\n",
    "        list_sentences_rev.append(row[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_words = [parsing(row) for row in list_sentences_rev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 各単語の頻度を数え上げる\n",
    "list_words_collection = []\n",
    "for row in list_words:\n",
    "    list_words_collection.extend(row)\n",
    "list_words_collection = collections.Counter(list_words_collection).items()\n",
    "\n",
    "# 除去語リストを作成\n",
    "list_words_remove = []\n",
    "for row in list_words_collection:\n",
    "    if row[1] < 3 or row[1] > 300:\n",
    "        list_words_remove.append(row[0])\n",
    "\n",
    "# 除去語リスト内の単語を削除\n",
    "list_words_rev = []\n",
    "for row in list_words:\n",
    "    list_words_tmp = []\n",
    "    for word in row:\n",
    "        if word in list_words_remove:\n",
    "            pass\n",
    "        else:\n",
    "            list_words_tmp.append(word)\n",
    "    list_words_rev.append(list_words_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 共起エッジリストの作成\n",
    "list_edges = []\n",
    "for row1 in list_words_rev:\n",
    "    list_tmp = list(itertools.combinations(row1,2))\n",
    "    for row2 in list_tmp:\n",
    "        list_edges.append(list(row2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writecsv(list_edges, \"./files/rakuten_corpus_edgelist_co.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 共起グラフ+windowでのエッジリスト作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# windowサイズ\n",
    "window = 1\n",
    "list_sentences = readtsv(\"./files/rakuten_corpus/annotation01_tsukuba_corpus_20140930.tsv\")\n",
    "# list_list_bgの形のデータを作る\n",
    "list_sentences_rev = []\n",
    "list_tmp = []\n",
    "for row in list_sentences:\n",
    "    if row[5] != '':\n",
    "        list_tmp.append(row[5])\n",
    "    else:\n",
    "        list_sentences_rev.append(list_tmp)\n",
    "        list_tmp = []\n",
    "else:\n",
    "    list_sentences_rev.append(list_tmp)\n",
    "\n",
    "list_words = [[parsing(sentence) for sentence in row] for row in list_sentences_rev]\n",
    "\n",
    "# 各単語の頻度を数え上げる\n",
    "list_words_collection = []\n",
    "for row in list_words:\n",
    "    for sentence in row:\n",
    "        list_words_collection.extend(sentence)\n",
    "list_words_collection = collections.Counter(list_words_collection).items()\n",
    "\n",
    "# 除去語リストを作成\n",
    "list_words_remove = []\n",
    "for row in list_words_collection:\n",
    "    if row[1] < 3 or row[1] > 300:\n",
    "        list_words_remove.append(row[0])\n",
    "\n",
    "# 除去語リスト内の単語を削除\n",
    "list_words_rev = []\n",
    "for row in list_words:\n",
    "    list_words_tmp1 = []\n",
    "    for sentence in row:\n",
    "        list_words_tmp2 = []\n",
    "        for word in sentence:\n",
    "            if word in list_words_remove:\n",
    "                pass\n",
    "            else:\n",
    "                list_words_tmp2.append(word)\n",
    "        list_words_tmp1.append(list_words_tmp2)\n",
    "    list_words_rev.append(list_words_tmp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_words_rev1 = [[num for word in row for num in word]for row in list_words_rev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "window = 3\n",
    "list_edges = []\n",
    "for row in list_words_rev1:\n",
    "    for i in range(len(row) - window):\n",
    "        list_tmp = list(itertools.combinations(row[i:i+window],2))\n",
    "        for row1 in list_tmp:\n",
    "            list_edges.append(row1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "writecsv(list_edges, \"./files/rakuten_corpus/rakuten_corpus_edgelist_window3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183015\n"
     ]
    }
   ],
   "source": [
    "list_words_rev2 = []\n",
    "# windowのサイズに従ったbgを作り直す\n",
    "for row in list_words_rev:\n",
    "    len_num = len(row)\n",
    "    for i, sentence in enumerate(row):\n",
    "        list_tmp = []\n",
    "        for num in range(i-window,i+window+1):\n",
    "            if num < 0 or num >= len_num:\n",
    "                continue\n",
    "            else:\n",
    "                list_tmp.extend(row[num])\n",
    "        list_words_rev2.append(list_tmp)\n",
    "        \n",
    "# 共起エッジリストの作成\n",
    "list_edges = []\n",
    "for row1 in list_words_rev2:\n",
    "    list_tmp = list(itertools.combinations(row1,2))\n",
    "    for row2 in list_tmp:\n",
    "        list_edges.append(list(row2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "writecsv(list_edges, \"./files/rakuten_corpus/rakuten_corpus_edgelist_window1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 共起グラフ+windowでのエッジリスト作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# windowサイズ\n",
    "window = 1\n",
    "# weight\n",
    "weight = 0.2\n",
    "list_sentences = readtsv(\"./files/rakuten_corpus/annotation01_tsukuba_corpus_20140930.tsv\")\n",
    "# list_list_bgの形のデータを作る\n",
    "list_sentences_rev = []\n",
    "list_tmp = []\n",
    "for row in list_sentences:\n",
    "    if row[5] != '':\n",
    "        list_tmp.append(row[5])\n",
    "    else:\n",
    "        list_sentences_rev.append(list_tmp)\n",
    "        list_tmp = []\n",
    "else:\n",
    "    list_sentences_rev.append(list_tmp)\n",
    "\n",
    "list_words = [[parsing(sentence) for sentence in row] for row in list_sentences_rev]\n",
    "\n",
    "# 各単語の頻度を数え上げる\n",
    "list_words_collection = []\n",
    "for row in list_words:\n",
    "    for sentence in row:\n",
    "        list_words_collection.extend(sentence)\n",
    "list_words_collection = collections.Counter(list_words_collection).items()\n",
    "\n",
    "# 除去語リストを作成\n",
    "list_words_remove = []\n",
    "for row in list_words_collection:\n",
    "    if row[1] < 3 or row[1] > 300:\n",
    "        list_words_remove.append(row[0])\n",
    "\n",
    "# 除去語リスト内の単語を削除\n",
    "list_words_rev = []\n",
    "for row in list_words:\n",
    "    list_words_tmp1 = []\n",
    "    for sentence in row:\n",
    "        list_words_tmp2 = []\n",
    "        for word in sentence:\n",
    "            if word in list_words_remove:\n",
    "                pass\n",
    "            else:\n",
    "                list_words_tmp2.append(word)\n",
    "        list_words_tmp1.append(list_words_tmp2)\n",
    "    list_words_rev.append(list_words_tmp1)\n",
    "\n",
    "list_edges = []\n",
    "# windowのサイズに従ったbgを作り直す\n",
    "for row in list_words_rev:\n",
    "    len_num = len(row)\n",
    "    for i, sentence in enumerate(row):\n",
    "        list_tmp = []\n",
    "        for num in range(i-window,i+window+1):\n",
    "            if num < 0 or num >= len_num:\n",
    "                continue\n",
    "            else:\n",
    "                if num == i:\n",
    "                    list_tmp = list(itertools.combinations(row[num],2))\n",
    "                    list_edges.extend([[tmp[0], tmp[1], 1] for tmp in list_tmp])\n",
    "                else:\n",
    "                    list_tmp = list(itertools.product(row[num], row[i]))\n",
    "                    list_edges.extend([[tmp[0], tmp[1], weight] for tmp in list_tmp])\n",
    "\n",
    "dict_edges = {}\n",
    "for row in list_edges:\n",
    "    tuple_tmp = tuple(sorted([row[0], row[1]]))\n",
    "    if tuple_tmp in dict_edges:\n",
    "        dict_edges[tuple_tmp] += row[2]\n",
    "    else:\n",
    "        dict_edges[tuple_tmp] = row[2]\n",
    "\n",
    "list_master = [[key[0], key[1], value] for key, value in dict_edges.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "writecsv(list_master, \"./files/rakuten_corpus/rakuten_corpus_edgelist_window_1_0.2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
