{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\"\"\"\n",
    "・cabochaによる構文取得\n",
    "・頻度を数え上げる\n",
    "・bag of wordsを作成する\n",
    "\"\"\"\n",
    "import CaboCha\n",
    "import xml.etree.ElementTree as ET\n",
    "from collections import Counter\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# csvファイルの読み込み\n",
    "def readcsv(path):\n",
    "    f = open(path, \"rb\")\n",
    "    dataReader = csv.reader(f)\n",
    "    arr = [row for row in dataReader]\n",
    "    return arr\n",
    "\n",
    "def parsing(sentence):\n",
    "    # cabochaのインスタンス化\n",
    "    c = CaboCha.Parser()\n",
    "    # 構文解析の結果をxmlで受け取る\n",
    "    xml = c.parse(sentence).toString(CaboCha.FORMAT_XML)\n",
    "    root = ET.fromstring(xml)\n",
    "    list_chunk = root.findall(\".//chunk\")\n",
    "    \n",
    "    # 後で処理しやすいようにdict型にしておく\n",
    "    dict_chunk = {}\n",
    "    # 後で順位和検定をするためにbag_of_wordsの作成をしておく\n",
    "    list_bag_of_words = []\n",
    "    for i, chunk in enumerate(list_chunk):\n",
    "        dict_chunk_tok = {\"id\": int(chunk.attrib[\"id\"]),\n",
    "                          \"link\": int(chunk.attrib[\"link\"]),\n",
    "                          \"head\": int(chunk.attrib[\"head\"]),\n",
    "                          \"tok_id\": [int(tok.attrib[\"id\"]) for tok in chunk.findall(\".//tok\")],\n",
    "                          \"tok_pos1\": [tok.attrib[\"feature\"].split(\",\")[0].encode(\"utf-8\") for tok in chunk.findall(\".//tok\")],\n",
    "                          \"tok_pos2\": [tok.attrib[\"feature\"].split(\",\")[1].encode(\"utf-8\") for tok in chunk.findall(\".//tok\")],\n",
    "                          \"tok_word\": [tok.attrib[\"feature\"].split(\",\")[6].encode(\"utf-8\") for tok in chunk.findall(\".//tok\")]}\n",
    "        dict_chunk[i] = dict_chunk_tok\n",
    "        list_bag_of_words.extend([tok.attrib[\"feature\"].split(\",\")[6] for tok in chunk.findall(\".//tok\") if tok.attrib[\"feature\"].split(\",\")[0].encode(\"utf-8\") in [\"名詞\", \"動詞\", \"形容詞\"]])\n",
    "    \n",
    "    # 最終的に返す配列\n",
    "    list_master = []\n",
    "    for i in range(len(dict_chunk)):\n",
    "        # 第２単語へのリンク\n",
    "        link = int(dict_chunk[i][\"link\"])\n",
    "        # もしリンクがなければその後の計算をしない\n",
    "        if link == -1:\n",
    "            continue\n",
    "        \n",
    "        # 第１単語について\n",
    "        head1 = dict_chunk[i][\"head\"]\n",
    "        tok_index1 = dict_chunk[i][\"tok_id\"].index(head1)\n",
    "        word1 = dict_chunk[i][\"tok_word\"][tok_index1]\n",
    "        main_pos1 = dict_chunk[i][\"tok_pos1\"][tok_index1]\n",
    "        sub_pos1 = dict_chunk[i][\"tok_pos2\"][tok_index1]\n",
    "        \n",
    "        # 第２単語について\n",
    "        head2 = dict_chunk[link][\"head\"]\n",
    "        tok_index2 = dict_chunk[link][\"tok_id\"].index(head2)\n",
    "        word2 = dict_chunk[link][\"tok_word\"][tok_index2]\n",
    "        main_pos2 = dict_chunk[link][\"tok_pos1\"][tok_index2]\n",
    "        sub_pos2 = dict_chunk[link][\"tok_pos2\"][tok_index2]\n",
    "        \n",
    "        # 選択した単語が「接尾語」だった場合、一つ前の単語にチェンジ\n",
    "        try:\n",
    "            if sub_pos1 == \"接尾\":\n",
    "                head1 = head1 - 1\n",
    "                tok_index1 = dict_chunk[i][\"tok_id\"].index(head1)\n",
    "                word1 = dict_chunk[i][\"tok_word\"][tok_index1]\n",
    "                main_pos1 = dict_chunk[i][\"tok_pos1\"][tok_index1]\n",
    "                sub_pos1 = dict_chunk[i][\"tok_pos2\"][tok_index1]\n",
    "            if sub_pos2 == \"接尾\":\n",
    "                head2 = head2 - 1\n",
    "                tok_index2 = dict_chunk[link][\"tok_id\"].index(head2)\n",
    "                word2 = dict_chunk[link][\"tok_word\"][tok_index2]\n",
    "                main_pos2 = dict_chunk[link][\"tok_pos1\"][tok_index2]\n",
    "                sub_pos2 = dict_chunk[link][\"tok_pos2\"][tok_index2]\n",
    "        except ValueError:\n",
    "            # たまに接尾語が先頭に入ってる場合がある、その場合はリストに入れない\n",
    "            print word1, word2\n",
    "            continue\n",
    "        \n",
    "        # 名詞 + 動詞, 名詞 + 形容詞, 名詞 + 名詞のセットだけ取ってくる\n",
    "        if set([main_pos1, main_pos2]) == set([\"名詞\", \"形容詞\"]):\n",
    "            if main_pos1 == \"名詞\" and sub_pos1 in [\"一般\", \"固有名詞\", \"サ変接続\", \"形容動詞語幹\"]:\n",
    "                list_master.append([word1 + \",\" + word2, sorted([head1, head2])])\n",
    "            elif main_pos2 == \"名詞\" and sub_pos2 in [\"一般\", \"固有名詞\", \"サ変接続\", \"形容動詞語幹\"]:\n",
    "                list_master.append([word2 + \",\" + word1, sorted([head2, head1])])\n",
    "        \n",
    "        elif set([main_pos1, main_pos2]) == set([\"名詞\", \"動詞\"]):\n",
    "            if main_pos1 == \"名詞\" and sub_pos1 in [\"一般\", \"固有名詞\", \"サ変接続\", \"形容動詞語幹\"]:\n",
    "                list_master.append([word1 + \",\" + word2, sorted([head1, head2])])\n",
    "            elif main_pos2 == \"名詞\" and sub_pos2 in [\"一般\", \"固有名詞\", \"サ変接続\", \"形容動詞語幹\"]:\n",
    "                list_master.append([word2 + \",\" + word1, sorted([head2, head1])])\n",
    "        \n",
    "        elif set([main_pos1, main_pos2]) == set([\"名詞\", \"名詞\"]):\n",
    "            if sub_pos1 in [\"一般\", \"固有名詞\", \"サ変接続\", \"形容動詞語幹\"] and sub_pos2 in [\"一般\", \"固有名詞\", \"サ変接続\", \"形容動詞語幹\"]:\n",
    "                list_master.append([word1 + \",\" + word2, sorted([head1, head2])])\n",
    "    \n",
    "    # 跨いでいる部分を削除\n",
    "    list_master_rev = []\n",
    "    for row_i in list_master:\n",
    "        list_i = range(row_i[1][0], row_i[1][1]+1)\n",
    "        for row_j in list_master:\n",
    "            list_j = range(row_j[1][0], row_j[1][1]+1)\n",
    "            if set(list_j).issubset(list_i) and len(list_j) < len(list_i):\n",
    "                break\n",
    "        else:\n",
    "            list_master_rev.append(row_i)\n",
    "    \n",
    "    return list_master_rev, list_bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              二階の-D      \n",
      "  居室だったのですが、-----D\n",
      "                  部屋の-D |\n",
      "                日当たりは-D\n",
      "                        良好\n",
      "EOS\n",
      "\n",
      "<sentence>\n",
      " <chunk id=\"0\" link=\"1\" rel=\"D\" score=\"4.751018\" head=\"1\" func=\"2\">\n",
      "  <tok id=\"0\" feature=\"名詞,数,*,*,*,*,二,ニ,ニ\">二</tok>\n",
      "  <tok id=\"1\" feature=\"名詞,接尾,助数詞,*,*,*,階,カイ,カイ\">階</tok>\n",
      "  <tok id=\"2\" feature=\"助詞,連体化,*,*,*,*,の,ノ,ノ\">の</tok>\n",
      " </chunk>\n",
      " <chunk id=\"1\" link=\"4\" rel=\"D\" score=\"-2.090361\" head=\"6\" func=\"8\">\n",
      "  <tok id=\"3\" feature=\"名詞,一般,*,*,*,*,居室,キョシツ,キョシツ\">居室</tok>\n",
      "  <tok id=\"4\" feature=\"助動詞,*,*,*,特殊・ダ,連用タ接続,だ,ダッ,ダッ\">だっ</tok>\n",
      "  <tok id=\"5\" feature=\"助動詞,*,*,*,特殊・タ,基本形,た,タ,タ\">た</tok>\n",
      "  <tok id=\"6\" feature=\"名詞,非自立,一般,*,*,*,の,ノ,ノ\">の</tok>\n",
      "  <tok id=\"7\" feature=\"助動詞,*,*,*,特殊・デス,基本形,です,デス,デス\">です</tok>\n",
      "  <tok id=\"8\" feature=\"助詞,接続助詞,*,*,*,*,が,ガ,ガ\">が</tok>\n",
      "  <tok id=\"9\" feature=\"記号,読点,*,*,*,*,、,、,、\">、</tok>\n",
      " </chunk>\n",
      " <chunk id=\"2\" link=\"3\" rel=\"D\" score=\"1.654702\" head=\"10\" func=\"11\">\n",
      "  <tok id=\"10\" feature=\"名詞,一般,*,*,*,*,部屋,ヘヤ,ヘヤ\">部屋</tok>\n",
      "  <tok id=\"11\" feature=\"助詞,連体化,*,*,*,*,の,ノ,ノ\">の</tok>\n",
      " </chunk>\n",
      " <chunk id=\"3\" link=\"4\" rel=\"D\" score=\"-2.090361\" head=\"12\" func=\"13\">\n",
      "  <tok id=\"12\" feature=\"名詞,一般,*,*,*,*,日当たり,ヒアタリ,ヒアタリ\">日当たり</tok>\n",
      "  <tok id=\"13\" feature=\"助詞,係助詞,*,*,*,*,は,ハ,ワ\">は</tok>\n",
      " </chunk>\n",
      " <chunk id=\"4\" link=\"-1\" rel=\"D\" score=\"0.000000\" head=\"14\" func=\"14\">\n",
      "  <tok id=\"14\" feature=\"名詞,形容動詞語幹,*,*,*,*,良好,リョウコウ,リョーコー\">良好</tok>\n",
      " </chunk>\n",
      "</sentence>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import CaboCha\n",
    "\n",
    "# c = CaboCha.Parser(\"\");\n",
    "c = CaboCha.Parser()\n",
    "\n",
    "sentence = \"二階の居室だったのですが、部屋の日当たりは良好\"\n",
    "\n",
    "print c.parseToString(sentence)\n",
    "\n",
    "tree =  c.parse(sentence)\n",
    "\n",
    "print tree.toString(CaboCha.FORMAT_XML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "助詞、助動詞をchunkから削除\n",
    "\"\"\"\n",
    "\n",
    "def debug_parsing(sentence):\n",
    "    # cabochaのインスタンス化\n",
    "    c = CaboCha.Parser()\n",
    "    # 構文解析の結果をxmlで受け取る\n",
    "    xml = c.parse(sentence).toString(CaboCha.FORMAT_XML)\n",
    "    root = ET.fromstring(xml)\n",
    "    list_chunk = root.findall(\".//chunk\")\n",
    "    \n",
    "    # 後で処理しやすいようにdict型にしておく\n",
    "    dict_chunk = {}\n",
    "    for i, chunk in enumerate(list_chunk):\n",
    "        dict_chunk_tok = {\"id\": int(chunk.attrib[\"id\"]),\n",
    "                          \"link\": int(chunk.attrib[\"link\"]),\n",
    "                          \"head\": int(chunk.attrib[\"head\"]),\n",
    "                          \"tok_id\": [],\n",
    "                          \"tok_pos1\": [],\n",
    "                          \"tok_pos2\": [],\n",
    "                          \"tok_word\": []}\n",
    "        for tok in chunk.findall(\".//tok\"):\n",
    "            features = tok.attrib[\"feature\"].encode(\"utf-8\").split(\",\")\n",
    "            if features[0] in [\"助詞\", \"助動詞\", \"記号\"]:\n",
    "                pass\n",
    "            else:\n",
    "                dict_chunk_tok[\"tok_id\"].append(tok.attrib[\"id\"])\n",
    "                dict_chunk_tok[\"tok_pos1\"].append(features[0])\n",
    "                dict_chunk_tok[\"tok_pos2\"].append(features[1])\n",
    "                dict_chunk_tok[\"tok_word\"].append(features[6])\n",
    "    \n",
    "        dict_chunk[i] = dict_chunk_tok\n",
    "        \n",
    "    return dict_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# csvファイルから文章を読み込んで、「。」を基準にセンテンスごとに分割する\n",
    "list_sentences = readcsv(\"./files/file_1.csv\")\n",
    "list_sentences = [row[1] for row in list_sentences]\n",
    "list_sentences_rev = []\n",
    "for row in list_sentences:\n",
    "    list_sentence = row.split(\"。\")\n",
    "    list_sentences_rev.extend(list_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====chunk: 0=====\n",
      "日々 名詞 副詞可能\n",
      "退屈 名詞 サ変接続\n",
      "=====chunk: 1=====\n",
      "なる 動詞 自立\n",
      "よう 名詞 非自立\n",
      "=====chunk: 2=====\n",
      "趣向 名詞 一般\n",
      "=====chunk: 3=====\n",
      "凝らす 動詞 自立\n",
      "れる 動詞 接尾\n",
      "=====chunk: 4=====\n",
      "* 名詞 一般\n",
      "=====chunk: 5=====\n",
      "ある 動詞 自立\n"
     ]
    }
   ],
   "source": [
    "dict_sentence = debug_parsing(list_sentences_rev[8])\n",
    "for i in range(len(dict_sentence)):\n",
    "    dict_tok = dict_sentence[i]\n",
    "    print \"=====chunk:\" + str(i) + \"=====\"\n",
    "    for j in range(len(dict_tok[\"tok_id\"])):\n",
    "        print dict_tok[\"tok_word\"][j], dict_tok[\"tok_pos1\"][j], dict_tok[\"tok_pos2\"][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
