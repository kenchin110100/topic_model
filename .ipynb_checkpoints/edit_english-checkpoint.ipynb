{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\"\"\"\n",
    "英語コーパスを編集するためのコード\n",
    "\"\"\"\n",
    "from library.filer import Filer\n",
    "import re\n",
    "import glob\n",
    "import random\n",
    "from stanford_corenlp_pywrapper import CoreNLP\n",
    "import collections\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Fileのパスを読み込み\n",
    "2. Edmundsの2009年分のデータセットを全て読み込む(約150車種分)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_path = glob.glob(\"../../../大学院/データセット/OpinRankDatasetWithJudgments/cars/data/2009/*\")\n",
    "\n",
    "list_all = []\n",
    "for path in list_path:\n",
    "    list_all.extend(Filer.readtxt(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 正規表現で<TEXT>の部分だけ読み込む\n",
    "2. 先頭の<TEXT>、文末の</TEXT>を削除する\n",
    "3. txt形式で保存する（約7000ユーザー分）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pattern = r'^<TEXT>'\n",
    "list_all_rev = []\n",
    "for row in list_all:\n",
    "    if re.match(pattern, row):\n",
    "        list_all_rev.append(row)\n",
    "        \n",
    "pattern1 = r'^<TEXT>'\n",
    "pattern2 = r'</TEXT>'\n",
    "list_all_rev1 = []\n",
    "for row in list_all_rev:\n",
    "    str1 = re.sub(pattern1, \"\", row)\n",
    "    str2 = re.sub(pattern2, \"\", str1)\n",
    "    list_all_rev1.append(str2)\n",
    "    \n",
    "Filer.writetxt(list_all_rev1, \"../../../大学院/データセット/OpinRankDatasetWithJudgments/cars_all_review_2009.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. リストをシャッフルする\n",
    "2. 1000ユーザー分だけを別のファイルに保存する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random.shuffle(list_all_rev1)\n",
    "\n",
    "Filer.writetxt(list_all_rev1[0:1000], \"../../../大学院/データセット/OpinRankDatasetWithJudgments/cars_all_review_2009_random1000.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 1000ユーザー分のコーパスを読み込み\n",
    "2. カンマで分割\n",
    "3. 改行コードを削除する\n",
    "4. tsvファイルにして保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_user = Filer.readtxt(\"../../../大学院/データセット/OpinRankDatasetWithJudgments/cars_all_review_2009_random1000.txt\")\n",
    "\n",
    "list_user_rev = []\n",
    "for row in list_user:\n",
    "    list_user_rev.append(row.split(\". \"))\n",
    "    \n",
    "list_user_rev1 = []\n",
    "pattern = r\"\\r\\n\"\n",
    "for row in list_user_rev:\n",
    "    list_tmp = []\n",
    "    for sentence in row:\n",
    "        sentence1 = re.sub(pattern, \"\", sentence)\n",
    "        if sentence1 != \"\":\n",
    "            list_tmp.append(sentence1)\n",
    "    list_user_rev1.append(list_tmp)\n",
    "    \n",
    "Filer.writetsv(list_user_rev1, \"../../../大学院/データセット/OpinRankDatasetWithJudgments/cars_all_review_2009_random1000_sep.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### edmunds 評価用コーパスを抜き出す\n",
    "\n",
    "1. 4人分のアノテーションを読み込む\n",
    "2. エラーデータがないか確認\n",
    "3. カンマで分割\n",
    "4. 改行コードを削除する\n",
    "5. tsvファイルにして保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 4人分のアノテーションを読み込む\n",
    "list_csv_f1 = Filer.readcsv(\"./files/edmunds/annotation/edmunds_annotation_former_flavia.csv\", option=\"rU\")\n",
    "list_csv_f2 = Filer.readcsv(\"./files/edmunds/annotation/edmunds_annotation_former_zhang.csv\", option=\"rU\")\n",
    "list_csv_l1 = Filer.readcsv(\"./files/edmunds/annotation/edmunds_annotation_latter_danilo.csv\", option=\"rU\")\n",
    "list_csv_l2 = Filer.readcsv(\"./files/edmunds/annotation/edmunds_annotation_latter_toshio.csv\", option=\"rU\")\n",
    "\n",
    "# どのデータも破損していないか、確認\n",
    "def check(list_csv, num=12):\n",
    "    for i, row in enumerate(list_csv):\n",
    "        if len(row) != num:\n",
    "            print \"Error:\", i\n",
    "\n",
    "check(list_csv_f1)\n",
    "check(list_csv_f2)\n",
    "check(list_csv_l1)\n",
    "check(list_csv_l2)\n",
    "        \n",
    "# 文番号をintに、空白に0を\"1\"をintに変換する\n",
    "def convert(list_csv):\n",
    "    for i, row in enumerate(list_csv):\n",
    "        list_csv[i][0] = int(list_csv[i][0])\n",
    "        list_csv[i][1] = int(list_csv[i][1])\n",
    "        for j in range(3,12):\n",
    "            if list_csv[i][j] == \"\":\n",
    "                list_csv[i][j] = 0\n",
    "            else:\n",
    "                list_csv[i][j] = 1\n",
    "    return list_csv\n",
    "\n",
    "list_csv_f1 = convert(list_csv_f1)\n",
    "list_csv_f2 = convert(list_csv_f2)\n",
    "list_csv_l1 = convert(list_csv_l1)\n",
    "list_csv_l2 = convert(list_csv_l2)\n",
    "\n",
    "# 2人の評価が同じものをデータセットとする\n",
    "def match(list_csv1, list_csv2):\n",
    "    list_csv_master = []\n",
    "    for row1, row2 in zip(list_csv1, list_csv2):\n",
    "        for i in range(3,11):\n",
    "            if sum(row1[3:]) == 1 and sum(row2[3:]) == 1:\n",
    "                if row1[i] == 1 and row2[i] == 1:\n",
    "                    list_tmp = row1[:3]\n",
    "                    list_tmp.append(i-3)\n",
    "                    list_csv_master.append(list_tmp)\n",
    "    return list_csv_master\n",
    "\n",
    "list_csv_former = match(list_csv_f1, list_csv_f2)\n",
    "list_csv_latter = match(list_csv_l1, list_csv_l2)\n",
    "# 文番号でソート\n",
    "list_csv_former = sorted(list_csv_former, key=lambda x:x[1])\n",
    "list_csv_latter = sorted(list_csv_latter, key=lambda x:x[1])\n",
    "# 1つのリストにまとめる\n",
    "list_master = []\n",
    "list_master.extend(list_csv_former)\n",
    "list_master.extend(list_csv_latter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Filer.writetsv(list_master, \"./files/edmunds/list_sentence_annotation.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Edmunds car reviewの語彙数と単語数を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3933\n",
      "18680\n",
      "1346\n"
     ]
    }
   ],
   "source": [
    "list_sentence_sep = Filer.readtsv(\"./files/edmunds/list_sentence_sep.tsv\")\n",
    "list_word = []\n",
    "for row in list_sentence_sep:\n",
    "    list_word.extend(row[3:])\n",
    "print len(list_sentence_sep)\n",
    "print len(list_word)\n",
    "print len(set(list_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### コーパス数を変えたデータセットを作るためのコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_path = glob.glob(\"files/edmunds/edmunds_corpus_master/2007/*\")\n",
    "list_path.extend(glob.glob(\"files/edmunds/edmunds_corpus_master/2008/*\"))\n",
    "list_path.extend(glob.glob(\"files/edmunds/edmunds_corpus_master/2009/*\"))\n",
    "list_all = []\n",
    "for path in list_path:\n",
    "    list_all.extend(Filer.readtxt(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pattern = r'^<TEXT>'\n",
    "list_all_rev = []\n",
    "for row in list_all:\n",
    "    if re.match(pattern, row):\n",
    "        list_all_rev.append(row)\n",
    "        \n",
    "pattern1 = r'^<TEXT>'\n",
    "pattern2 = r'</TEXT>'\n",
    "list_all_rev1 = []\n",
    "for row in list_all_rev:\n",
    "    str1 = re.sub(pattern1, \"\", row)\n",
    "    str2 = re.sub(pattern2, \"\", str1)\n",
    "    list_all_rev1.append(str2.replace(\"\\r\\n\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_num = [i*1000 for i in range(1,10)]\n",
    "list_num.extend([i*10000 for i in range(1,5)])\n",
    "\n",
    "dict_sentence = {}\n",
    "for num in list_num:\n",
    "    dict_sentence[num] = random.sample(list_all_rev1, num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for num in list_num:\n",
    "    Filer.writetxt(dict_sentence[num], \"files/edmunds/edmunds_corpus_master/userfile/edmunds_user_%s.txt\" % num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pattern = re.compile('\\. |! |\\? ')\n",
    "dict_sentence_rev = {}\n",
    "for num in list_num:\n",
    "    dict_sentence_rev[num] = []\n",
    "    for review in dict_sentence[num]:\n",
    "        for sentence in re.split(pattern, review):\n",
    "            if len(sentence) > 1:\n",
    "                 dict_sentence_rev[num].append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for num in list_num:\n",
    "    Filer.writetxt(dict_sentence_rev[num], \"files/edmunds/edmunds_corpus_master/sentencefile/edmunds_sentence_%s.txt\" % num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### テストデータセットの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:CoreNLP_PyWrapper:Starting java subprocess, and waiting for signal it's ready, with command: exec java -Xmx4g -XX:ParallelGCThreads=1 -cp '/home/ikegami/ikegami/lib/python2.7/site-packages/stanford_corenlp_pywrapper/lib/*:/home/ikegami/lib/stanford-corenlp-full-2015-04-20/*'      corenlp.SocketServer --outpipe /tmp/corenlp_pywrap_pipe_pypid=23656_time=1466060720.93  --configdict '{\"annotators\": \"tokenize,ssplit,pos, lemma\"}'\n",
      "INFO:CoreNLP_PyWrapper:Successful ping. The server has started.\n",
      "INFO:CoreNLP_PyWrapper:Subprocess is ready.\n"
     ]
    }
   ],
   "source": [
    "list_testfile = Filer.readtsv(\"./files/edmunds/list_sentence_annotation.tsv\")\n",
    "proc = CoreNLP(configdict={'annotators': 'tokenize,ssplit,pos, lemma'}, corenlp_jars=[\"/home/ikegami/lib/stanford-corenlp-full-2015-04-20/*\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_sepword = []\n",
    "for _, _, sentence, label in list_testfile:\n",
    "    pattern1 = r'^NN'\n",
    "    pattern2 = r'^VB'\n",
    "    pattern3 = r'^JJ'\n",
    "    try:\n",
    "        dict_tmp = proc.parse_doc(sentence)\n",
    "        list_sepword_tmp = []\n",
    "        for lemma, pos in zip(dict_tmp[u'sentences'][0][u'lemmas'], dict_tmp[u'sentences'][0][u'pos']):\n",
    "            if re.match(pattern1, pos) or re.match(pattern2, pos) or re.match(pattern3, pos):\n",
    "                list_sepword_tmp.append(lemma.encode('utf-8'))\n",
    "        list_sepword.append([list_sepword_tmp, label])\n",
    "    except UnicodeError:\n",
    "        print \"error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Filer.writedump(list_sepword, './files/edmunds/edmunds_corpus_master/testfile/list_sepword_label.dump')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テストデータセットの作成(削除語なし)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_testfile = Filer.readtsv(\"./files/edmunds/list_sentence_annotation.tsv\")\n",
    "proc = CoreNLP(configdict={'annotators': 'tokenize,ssplit,pos, lemma'}, corenlp_jars=[\"/home/ikegami/lib/stanford-corenlp-full-2015-04-20/*\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_sepword = []\n",
    "for _, _, sentence, label in list_testfile:\n",
    "    try:\n",
    "        dict_tmp = proc.parse_doc(sentence)\n",
    "        list_sepword_tmp = []\n",
    "        for lemma, pos in zip(dict_tmp[u'sentences'][0][u'lemmas'], dict_tmp[u'sentences'][0][u'pos']):\n",
    "            if lemma.encode('utf-8') != ',' and lemma.encode('utf-8') != '.':\n",
    "                list_sepword_tmp.append(lemma.encode('utf-8'))\n",
    "        list_sepword.append([list_sepword_tmp, label])\n",
    "    except UnicodeError:\n",
    "        print \"error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Filer.writedump(list_sepword, './files/edmunds/edmunds_corpus_master/testfile/list_sepword_label_type3.dump')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
