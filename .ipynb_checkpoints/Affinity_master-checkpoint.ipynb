{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\"\"\"\n",
    "Affinity propagationでクラスタリングするためのコード\n",
    "\"\"\"\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import adjusted_mutual_info_score, adjusted_rand_score, completeness_score, homogeneity_completeness_v_measure, homogeneity_score, normalized_mutual_info_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from library.filer import Filer\n",
    "from library.dnp import Evaluation\n",
    "import glob\n",
    "from scipy import sparse\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_tfidf(list_word, list_test):\n",
    "    set_word = set([word for row in list_word for word in row])\n",
    "    V = len(set_word)\n",
    "    D = len(list_word)\n",
    "    D_test = len(list_test)\n",
    "    dict_word_id = {word:i for i, word in enumerate(set_word)}\n",
    "    \n",
    "    list_dict_id = [collections.Counter([dict_word_id[word] for word in list_word[d]\n",
    "                                          if word in dict_word_id]) for d in range(D)]\n",
    "\n",
    "    list_dict_id_test = [collections.Counter([dict_word_id[word] for word in list_test[d]\n",
    "                                               if word in dict_word_id]) for d in range(D_test)]\n",
    "    \n",
    "    list_row = []\n",
    "    list_col = []\n",
    "    list_data = []\n",
    "    list_row_test = []\n",
    "    list_col_test = []\n",
    "    list_data_test = []\n",
    "    \n",
    "    for d in range(D):\n",
    "        for key, value in list_dict_id[d].items():\n",
    "            list_row.append(d)\n",
    "            list_col.append(key)\n",
    "            list_data.append(value)\n",
    "            \n",
    "    for d in range(D_test):\n",
    "        for key, value in list_dict_id_test[d].items():\n",
    "            list_row_test.append(d)\n",
    "            list_col_test.append(key)\n",
    "            list_data_test.append(value)\n",
    "    \n",
    "    # idfの計算\n",
    "    dict_word_num = collections.Counter(list_col)\n",
    "    list_key, list_value = zip(*dict_word_num.items())\n",
    "    list_value = np.array(list_value)\n",
    "    list_idf = np.log(float(D)/list_value) + 1\n",
    "    \n",
    "    for i in range(len(list_col)):\n",
    "        list_data[i] *= list_idf[list_col[i]]\n",
    "    \n",
    "    for i in range(len(list_col_test)):\n",
    "        list_data_test[i] *= list_idf[list_col_test[i]]\n",
    "                         \n",
    "    list_d_w = sparse.csr_matrix((list_data, (list_row, list_col)), shape=(D, V), dtype=np.float)\n",
    "    list_d_w_test = sparse.csr_matrix((list_data_test, (list_row_test, list_col_test)),\n",
    "                                      shape=(D_test, V), dtype=np.float)                     \n",
    "                         \n",
    "    return list_d_w, list_d_w_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_filepath = glob.glob('files/rakuten_corpus/rakuten_corpus_master/preprocessedfile/type2/forUM/*.txt')\n",
    "list_filepath.sort()\n",
    "list_testfile = Filer.readdump('./files/rakuten_corpus/rakuten_corpus_master/testfile/list_sepword_label.dump')\n",
    "list_testword = [row[0] for row in list_testfile]\n",
    "list_label = [row[1] for row in list_testfile]\n",
    "\n",
    "outputpath = './files/result/rakuten/experiment4/Affinity.txt'\n",
    "removepath = 'files/rakuten_corpus/rakuten_corpus_master/preprocessedfile/type2/forUM/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files/rakuten_corpus/rakuten_corpus_master/preprocessedfile/type2/forUM/rakuten_preprocessed_005105.txt\n"
     ]
    }
   ],
   "source": [
    "for path in list_filepath:\n",
    "    print path\n",
    "    path_rev = path.replace(removepath, '')\n",
    "    Filer.writetxt([path_rev], outputpath)\n",
    "    \n",
    "    list_word = Filer.readtxt(path)\n",
    "    list_d_w, list_d_w_test = cal_tfidf(list_word, list_testword)\n",
    "    \n",
    "    affinity = AffinityPropagation()\n",
    "    affinity.fit(list_d_w)\n",
    "    \n",
    "    K = len(set(affinity.labels_))\n",
    "    \n",
    "    list_predict = affinity.predict(list_d_w_test)\n",
    "\n",
    "    eva = Evaluation()\n",
    "    dict_result = eva.cal_f_measure(list_predict, list_label)\n",
    "        \n",
    "    # NMI\n",
    "    NMI = normalized_mutual_info_score(list_label, list_predict)\n",
    "    # vm\n",
    "    H, C, VM = homogeneity_completeness_v_measure(list_label, list_predict)\n",
    "    # ARI\n",
    "    ARI = adjusted_rand_score(list_label, list_predict)\n",
    "    # AMI\n",
    "    AMI = adjusted_mutual_info_score(list_label, list_predict)\n",
    "        \n",
    "    Filer.writetxt([' '.join([str(dict_result['purity']),str(dict_result['invpurity']),str(dict_result['fvalue']),\n",
    "                              str(NMI), str(H), str(C), str(VM), str(ARI), str(AMI), str(K)])],\n",
    "                    outputpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
