{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\"\"\"\n",
    "rakuten_corpus用\n",
    "tetsuo_hiro.csvで評価\n",
    "\"\"\"\n",
    "from igraph import *\n",
    "import csv\n",
    "import collections\n",
    "import pickle\n",
    "import numpy as np\n",
    "from openopt import QP\n",
    "\n",
    "# csvファイルの読み込み\n",
    "def readcsv(path):\n",
    "    f = open(path, \"rb\")\n",
    "    dataReader = csv.reader(f)\n",
    "    arr = [row for row in dataReader]\n",
    "    return arr\n",
    "\n",
    "def writecsv(arr, path):\n",
    "    f = open(path, \"ab\")\n",
    "    dataWriter = csv.writer(f)\n",
    "    dataWriter.writerows(arr)\n",
    "    f.close()\n",
    "\n",
    "def readdump(path):\n",
    "    f = open(path, \"r\")\n",
    "    arr = pickle.load(f)\n",
    "    f.close()\n",
    "    return arr\n",
    "\n",
    "# 有向エッジリストを入力して、重み付き無向ネットワークを出力する\n",
    "def cal_edgelist_to_network(list_edge):\n",
    "    # 有向エッジリストを無向エッジリストに変換する\n",
    "    list_edge = [tuple(sorted(row)) for row in list_edge]\n",
    "    # ノードリスト\n",
    "    list_vertices = list(set([word for row in list_edge for word in row]))\n",
    "    # エッジリストとそのweightを作成\n",
    "    tuple_edge, tuple_weight = zip(*collections.Counter(list_edge).items())\n",
    "    return {\"vertex\": list_vertices, \"edge\": list(tuple_edge), \"weight\": list(tuple_weight)}\n",
    "\n",
    "# クラスタリング済みのネットワークを元にサブグラフのリストを作成\n",
    "# vertexには全てのvertexを代入する（PageRankを計算するため）\n",
    "def cal_cluster_to_network(dict_network):\n",
    "    if dict_network.has_key(\"cluster\") == False:\n",
    "        print \"クラスタリングができていません\"\n",
    "    \n",
    "    # クラスタごとにwordをまとめる\n",
    "    dict_cluster = collections.defaultdict(list)\n",
    "    for word, cluster in zip(dict_network[\"vertex\"], dict_network[\"cluster\"]):\n",
    "        dict_cluster[cluster].append(word)\n",
    "\n",
    "    # リストに変換\n",
    "    list_cluster_vertex = [row[1] for row in dict_cluster.items()]\n",
    "    \n",
    "    # 同様にエッジとウェイトのリストも作成する\n",
    "    list_cluster_edge = []\n",
    "    list_cluster_weight = []\n",
    "    for cluster_vertex in list_cluster_vertex:\n",
    "        list_cluster_edge_one = []\n",
    "        list_cluster_weight_one = []\n",
    "        # エッジリストの中に、一つでもノードが含まれていれば、そのクラスのノードに含める\n",
    "        for row, weight in zip(dict_network[\"edge\"], dict_network[\"weight\"]):\n",
    "            # and と or を切り替えることによって性能の比較\n",
    "            if row[0] in cluster_vertex or row[1] in cluster_vertex:\n",
    "                list_cluster_edge_one.append(row)\n",
    "                list_cluster_weight_one.append(weight)\n",
    "        list_cluster_edge.append(list_cluster_edge_one)\n",
    "        list_cluster_weight.append(list_cluster_weight_one)\n",
    "    \n",
    "    # まとめる\n",
    "    list_dict_network = [{\"vertex\": dict_network[\"vertex\"],\n",
    "                          \"edge\": cluster_edge,\n",
    "                          \"weight\": cluster_weight}\n",
    "                         for cluster_edge, cluster_weight\n",
    "                         in zip(list_cluster_edge, list_cluster_weight)]\n",
    "    \n",
    "    return list_dict_network\n",
    "\n",
    "# f_measureを計算する\n",
    "def cal_f_measure(list_predict_measure):\n",
    "    # 生成したクラスタ内のカウント\n",
    "    dict_predict_cluster = collections.defaultdict(list)\n",
    "    for row in list_predict_measure:\n",
    "        dict_predict_cluster[row[0]].append(row[1])\n",
    "        \n",
    "    # もとあるクラス内のカウント\n",
    "    dict_measure_cluster = collections.defaultdict(list)\n",
    "    for row in list_predict_measure:\n",
    "        dict_measure_cluster[row[1]].append(row[0])\n",
    "    \n",
    "    # local_purityの計算\n",
    "    list_purity = []\n",
    "    for row in dict_predict_cluster.items():\n",
    "        major_class = sorted(collections.Counter(row[1]).items(), key=lambda x: x[1], reverse=True)[0][1]\n",
    "        class_num = len(row[1])\n",
    "        list_purity.append([major_class, class_num])\n",
    "    purity = float(np.sum(zip(*list_purity)[0])) / np.sum(zip(*list_purity)[1])\n",
    "    print \"Purity: \", purity\n",
    "    \n",
    "    # inverse_purityの計算\n",
    "    list_inverse_purity = []\n",
    "    for row in dict_measure_cluster.items():\n",
    "        major_class = sorted(collections.Counter(row[1]).items(), key=lambda x: x[1], reverse=True)[0][1]\n",
    "        class_num = len(row[1])\n",
    "        list_inverse_purity.append([major_class, class_num])\n",
    "    inverse_purity = float(np.sum(zip(*list_inverse_purity)[0])) / np.sum(zip(*list_inverse_purity)[1])\n",
    "    print \"Inverse Purity: \", inverse_purity\n",
    "    \n",
    "    print \"F-value: \", 2 / (1 / purity + 1 / inverse_purity)\n",
    "    \n",
    "# 凸２次計画問題を解いてp(topic)を求めるための関数\n",
    "def cal_prob_topic(dict_network_master, list_dict_network_sub):\n",
    "    prob_master = np.array([row[1] for row in sorted(zip(dict_network_master[\"vertex\"], dict_network_master[\"page_rank\"]), key=lambda x: x[0])])\n",
    "    \n",
    "    for i, dict_network_sub in enumerate(list_dict_network_sub):\n",
    "        if i == 0:\n",
    "            prob_sub = np.array([row[1] for row in sorted(zip(dict_network_sub[\"vertex\"], dict_network_sub[\"page_rank\"]), key=lambda x: x[0])])\n",
    "        else:\n",
    "            list_tmp = np.array([row[1] for row in sorted(zip(dict_network_sub[\"vertex\"], dict_network_sub[\"page_rank\"]), key=lambda x: x[0])])\n",
    "            prob_sub = np.vstack((prob_sub, list_tmp))\n",
    "    \n",
    "    H = 2 * prob_sub.dot(prob_sub.T)\n",
    "    f = -2 * prob_master.dot(prob_sub.T)\n",
    "    Aeq = np.ones(len(list_dict_network_sub))\n",
    "    beq = 1\n",
    "    lb = np.zeros(len(list_dict_network_sub))\n",
    "    \n",
    "    p = QP(H, f, Aeq=Aeq, beq=beq, lb=lb)\n",
    "    r = p.solve(\"cvxopt_qp\")\n",
    "    k_opt = r.xf\n",
    "    return k_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###メイン部分\n",
    "1. 有向エッジリストから無向重み付きエッジリストを作成\n",
    "2. louvain法によるクラスタリング\n",
    "3. クラスタごとにpagerankを計算し、p(word|topic)とする\n",
    "4. クラスタごとにp(word|topic)を出力する辞書を作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "クラスタ数:  10\n",
      "\n",
      "------------------------- OpenOpt 0.5625 -------------------------\n",
      "problem: unnamed   type: QP\n",
      "solver: cvxopt_qp\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.6156e-03 -1.0041e+00  1e+00  3e-17  3e+00\n",
      " 1: -2.6180e-03 -1.4111e-02  1e-02  7e-17  4e-02\n",
      " 2: -2.7662e-03 -3.8864e-03  1e-03  1e-16  4e-03\n",
      " 3: -3.0274e-03 -3.1978e-03  2e-04  5e-17  1e-18\n",
      " 4: -3.0639e-03 -3.0857e-03  2e-05  7e-17  2e-18\n",
      " 5: -3.0698e-03 -3.0724e-03  3e-06  1e-16  2e-18\n",
      " 6: -3.0704e-03 -3.0705e-03  2e-07  6e-17  2e-18\n",
      " 7: -3.0704e-03 -3.0704e-03  5e-09  7e-17  2e-18\n",
      "Optimal solution found.\n",
      "istop: 1000 (optimal)\n",
      "Solver:   Time Elapsed = 0.0 \tCPU Time Elapsed = 0.0\n",
      "objFuncValue: -0.0030704392 (feasible, MaxResidual = 0)\n"
     ]
    }
   ],
   "source": [
    "# エッジリストの読み込み\n",
    "list_edge = readcsv(\"./files/rakuten_corpus/rakuten_corpus_edgelist.csv\")\n",
    "# 元のネットワークを作成する（無向）\n",
    "dict_network_master = cal_edgelist_to_network(list_edge)\n",
    "# g = Graph(directed=True)\n",
    "g_master = Graph()\n",
    "g_master.add_vertices(dict_network_master[\"vertex\"])\n",
    "g_master.add_edges(dict_network_master[\"edge\"])\n",
    "# louvain法によるクラスタリング、vertexと同じ長さのクラスタ番号が書かれたリストがreturn\n",
    "dict_network_master[\"cluster\"] = g_master.community_fastgreedy(weights=dict_network_master[\"weight\"]).as_clustering().membership\n",
    "# 元のネットワークのpagerankを求める\n",
    "dict_network_master[\"page_rank\"] = g_master.pagerank(directed=False, weights=dict_network_master[\"weight\"])\n",
    "# クラスタ結果をもとにサブグラフのリストを作成\n",
    "list_dict_network_sub = cal_cluster_to_network(dict_network_master)\n",
    "# サブクラスタごとに中心性の計算\n",
    "for i, dict_network_sub in enumerate(list_dict_network_sub):\n",
    "    g_sub = Graph()\n",
    "    g_sub.add_vertices(dict_network_sub[\"vertex\"])\n",
    "    g_sub.add_edges(dict_network_sub[\"edge\"])\n",
    "    list_dict_network_sub[i][\"center_bet\"] = g_sub.betweenness(directed=False, weights=dict_network_sub[\"weight\"])\n",
    "    list_dict_network_sub[i][\"center_eigen\"] = g_sub.eigenvector_centrality(directed=False, weights=dict_network_sub[\"weight\"])\n",
    "    list_dict_network_sub[i][\"page_rank\"] = g_sub.pagerank(directed=False, weights=dict_network_sub[\"weight\"])\n",
    "print \"クラスタ数: \", len(list_dict_network_sub)\n",
    "\n",
    "# トピックごとにwordを入力したらp(word|topic)が出るような辞書を作成\n",
    "list_dict_prob = []\n",
    "for i in range(len(list_dict_network_sub)):\n",
    "    list_word_page = sorted(zip(list_dict_network_sub[i][\"vertex\"], list_dict_network_sub[i][\"page_rank\"]), key=lambda x: x[1], reverse=True)\n",
    "    list_dict_prob.append({row[0]: row[1] for row in list_word_page})\n",
    "    \n",
    "# 凸２次計画問題を解いて、p(topic)を求める\n",
    "list_prob_topic = cal_prob_topic(dict_network_master, list_dict_network_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ナイト 0.0360174104079\n",
      "ウェア 0.0127372720375\n",
      "対応 0.00458367266569\n",
      "ポイント 0.00277922579372\n",
      "JR 0.00277922579372\n",
      "長崎 0.00277922579372\n",
      "浴衣 0.00277922579372\n",
      "申し分 0.00277922579372\n",
      "ユニットバス 0.00277922579372\n",
      "車 0.00277922579372\n"
     ]
    }
   ],
   "source": [
    "num = 9\n",
    "list_tmp = sorted(list_dict_prob[num].items(), key=lambda x: x[1], reverse=True)\n",
    "for i in range(10):\n",
    "    print list_tmp[i][0], list_tmp[i][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定量評価部分\n",
    "1. 形態素解析済みセンテンスを読み込み、確率を計算し、どのクラスに属するか計算\n",
    "2. 予測クラスと実際クラスのリストを作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_dict_words = dict_network_master[\"vertex\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_sep_words = readdump(\"./files/rakuten_corpus/annotation/hiro_tetsuo_sep.dump\")\n",
    "list_sep_words_rev = []\n",
    "for row in list_sep_words:\n",
    "    list_tmp = []\n",
    "    for word in row[1]:\n",
    "        if word in list_dict_words:\n",
    "            list_tmp.append(word)\n",
    "    if row[2] != 6:\n",
    "        list_sep_words_rev.append([list_tmp, row[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2178"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_sep_words_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "エラーデータ数:  0\n"
     ]
    }
   ],
   "source": [
    "# 確率が最大になるクラスを予想する\n",
    "# 実質ラベルがintじゃない場合は、エラーとして、記録しない\n",
    "list_predict_measure = []\n",
    "list_words_rev = []\n",
    "error_count = 0\n",
    "for row in list_sep_words_rev:\n",
    "    try:\n",
    "        class_tmp = 0\n",
    "        prob_tmp = 0\n",
    "        predict_class = []\n",
    "        for num, dict_prob in enumerate(list_dict_prob):\n",
    "            prob_tmp_tmp = 1\n",
    "            for word in row[0]:\n",
    "                prob_tmp_tmp *= float(dict_prob[word])\n",
    "            prob_tmp_tmp *= list_prob_topic[num]\n",
    "            if prob_tmp_tmp > prob_tmp:\n",
    "                class_tmp = num\n",
    "                prob_tmp = prob_tmp_tmp\n",
    "        list_predict_measure.append([class_tmp, row[1]])\n",
    "    except:\n",
    "        error_count += 1\n",
    "print \"エラーデータ数: \", error_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###計算結果の表示\n",
    "* 7クラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity:  0.577594123049\n",
      "Inverse Purity:  0.644168962351\n",
      "F-value:  0.609067684808\n"
     ]
    }
   ],
   "source": [
    "cal_f_measure(list_predict_measure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###計算結果の表示\n",
    "* 10クラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity:  0.582185491276\n",
      "Inverse Purity:  0.644628099174\n",
      "F-value:  0.61181768694\n"
     ]
    }
   ],
   "source": [
    "cal_f_measure(list_predict_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
