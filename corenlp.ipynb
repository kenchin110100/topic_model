{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\"\"\"\n",
    "corenlpを使って形態素解析を行って学習用のファイルを作成する\n",
    "\"\"\"\n",
    "from stanford_corenlp_pywrapper import CoreNLP\n",
    "from library.filer import Filer\n",
    "import re\n",
    "import collections\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 形態素解析する600ユーザー分のレビューを取得\n",
    "2. CoreNLPの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_sentence = Filer.readtsv(\"../../../大学院/データセット/OpinRankDatasetWithJudgments/cars_all_review_2009_random1000_sep.tsv\")\n",
    "\n",
    "proc = CoreNLP(configdict={'annotators': 'tokenize,ssplit,pos, lemma'}, corenlp_jars=[\"/usr/local/lib/stanford-corenlp-full-2015-04-20/*\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 形態素解析を行って、NN, VB, JJに限定して単語を取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n",
      "error\n"
     ]
    }
   ],
   "source": [
    "pattern1 = r'^NN'\n",
    "pattern2 = r'^VB'\n",
    "pattern3 = r'^JJ'\n",
    "\n",
    "list_sentence_sep=[]\n",
    "list_sentence_rev = []\n",
    "for row in list_sentence[0:600]:\n",
    "    list_user_tmp = []\n",
    "    list_sentence_tmp = []\n",
    "    for sentence in row:\n",
    "        list_sen_tmp = []\n",
    "        try:\n",
    "            dict_tmp = proc.parse_doc(sentence)\n",
    "            for lemma, pos in zip(dict_tmp[u'sentences'][0][u'lemmas'], dict_tmp[u'sentences'][0][u'pos']):\n",
    "                if re.match(pattern1, pos) or re.match(pattern2, pos) or re.match(pattern3, pos):\n",
    "                    list_sen_tmp.append(lemma)\n",
    "            list_user_tmp.append(list_sen_tmp)\n",
    "            list_sentence_tmp.append(sentence)\n",
    "        except UnicodeError:\n",
    "            print \"error\"\n",
    "    list_sentence_sep.append(list_user_tmp)\n",
    "    list_sentence_rev.append(list_sentence_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 単語を除去する前の語彙数と語数をチェック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27385\n",
      "3975\n"
     ]
    }
   ],
   "source": [
    "list_words = [word for row1 in list_sentence_sep for row2 in row1 for word in row2]\n",
    "print len(list_words)\n",
    "print len(set(list_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 出現頻度300以上、2以下の単語は除去語として、登録\n",
    "2. 除去語を形態素解析した結果から削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_tmp = [sen for row1 in list_sentence_sep for row2 in row1 for sen in row2]\n",
    "list_count = sorted(collections.Counter(list_tmp).items(), key=lambda x: x[1], reverse=True)\n",
    "list_remove = [row[0] for row in list_count if row[1] >= 300 or row[1] <= 2]\n",
    "\n",
    "list_sentence_sep_rev = []\n",
    "for row1 in list_sentence_sep:\n",
    "    list_sentence_tmp = []\n",
    "    for row2 in row1:\n",
    "        list_tmp = []\n",
    "        for word in row2:\n",
    "            if word not in list_remove:\n",
    "                list_tmp.append(word.encode(\"utf-8\"))\n",
    "        list_sentence_tmp.append(list_tmp)\n",
    "    list_sentence_sep_rev.append(list_sentence_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. userID, sentenceID, sentence, sep_wordsという形式のリストを作成\n",
    "2. tsv形式でファイルを保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_all = []\n",
    "counter_user = 0\n",
    "counter_sen = 0\n",
    "for row_sen, row_sep in zip(list_sentence_rev, list_sentence_sep_rev):\n",
    "    counter_sen = 0\n",
    "    for sen, sep in zip(row_sen, row_sep):\n",
    "        list_tmp = [counter_user, counter_sen, sen]\n",
    "        list_tmp.extend(sep)\n",
    "        counter_sen += 1\n",
    "        list_all.append(list_tmp)\n",
    "    counter_user += 1\n",
    "    \n",
    "Filer.writetsv(list_all, \"./files/edmunds_car/list_sentence_sep.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. UserID, sentenceID, sentence, sepを記録したtsvファイルを読み込む\n",
    "2. sepの部分のみ抜き出す\n",
    "3. itertoolsを使ってエッジリストを作成\n",
    "4. csvファイルとしてエッジリストを保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_all = Filer.readtsv(\"./files/edmunds_car/list_sentence_sep.tsv\")\n",
    "\n",
    "list_all = [row[3:] for row in list_all]\n",
    "\n",
    "list_edgelist = []\n",
    "for row in list_all:\n",
    "    list_tmp = list(itertools.combinations(row,2))\n",
    "    list_edgelist.extend(list_tmp)\n",
    "    \n",
    "Filer.writecsv(list_edgelist, \"./files/edmunds_car/list_edgelist_edmunds_co.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "1. UserID, sentenceID, sentence, sepを記録したtsvファイルを読み込む\n",
    "2. sepの部分のみ抜き出す\n",
    "3. UM用の学習ファイルとして、txtファイルとして保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_all = Filer.readtsv(\"./files/edmunds/list_sentence_sep.tsv\")\n",
    "\n",
    "list_all = [\" \".join(row[3:]) for row in list_all]\n",
    "\n",
    "Filer.writetxt(list_all, \"./files/edmunds/edmunds_corpus_for_UM.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. UserID, sentenceID, sentence, sepを記録したtsvファイルを読み込む\n",
    "2. UserID, sentenceID, sentenceの部分のみ抜き出す\n",
    "3. sentencesIDを付け直す\n",
    "4. tsvファイルに保存する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_all = Filer.readtsv(\"./files/edmunds/list_sentence_sep.tsv\")\n",
    "\n",
    "list_all = [row[:3] for row in list_all]\n",
    "\n",
    "list_all_rev = []\n",
    "for i, row in enumerate(list_all):\n",
    "    list_all_rev.append([row[0], i, row[2]])\n",
    "    \n",
    "Filer.writetsv(list_all_rev, \"./files/edmunds/edmunds_annotation.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. UserID, sentenceID, sentence, sepを記録したtsvファイルを読み込む\n",
    "2. sentencesIDを付け直す\n",
    "3. tsvファイルに保存する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_all = Filer.readtsv(\"./files/edmunds/list_sentence_sep.tsv\")\n",
    "\n",
    "for i, row in enumerate(list_all):\n",
    "    list_all[i][1] = i\n",
    "    \n",
    "Filer.writetsv(list_all, \"./files/edmunds/list_sentence_sep_rev.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = Filer.readdump(\"./files/rakuten_corpus/annotation/all_sep.dump\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 評価用のダンプファイルを作成する\n",
    "* [sentenceID, label, [sepwords]]\n",
    "* その際に、空の配列は消すようにする\n",
    "1. list_sentence_sep.tsv, list_sentence_annotation.tsvを読み込み\n",
    "2. 配列の作成\n",
    "3. 形態素の数が0のものを除く\n",
    "4. それぞれのラベルが何個ずつあるのかカウントする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 125), (1, 149), (2, 102), (3, 106), (4, 352), (5, 168), (6, 71), (7, 75)]\n"
     ]
    }
   ],
   "source": [
    "# コーパスの読み込み\n",
    "list_sentence_sep = Filer.readtsv(\"./files/edmunds/list_sentence_sep.tsv\")\n",
    "list_sentence_annotation = Filer.readtsv(\"./files/edmunds/list_sentence_annotation.tsv\")\n",
    "\n",
    "# key: id, value: list_sepの辞書を作成\n",
    "dict_id_sep = {int(row[1]): row[3:] for row in list_sentence_sep}\n",
    "# [sentenceID, label, [sepwords]]の配列を作成、ただし、形態素数が0の場合は除く\n",
    "list_id_label_sep = [[int(row[1]), int(row[3]), dict_id_sep[int(row[1])]] for row in list_sentence_annotation if len(dict_id_sep[int(row[1])]) != 0]\n",
    "list_label = [row[1] for row in list_id_label_sep]\n",
    "print sorted(collections.Counter(list_label).items(), key=lambda x:x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Filer.writedump(list_id_label_sep, \"./files/edmunds/list_id_label_sep.dump\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA用の学習データを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_all = Filer.readtsv(\"./files/edmunds/list_sentence_sep.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict_id_sep = {}\n",
    "for row in list_all:\n",
    "    if int(row[0]) in dict_id_sep:\n",
    "        dict_id_sep[int(row[0])].extend(row[3:])\n",
    "    else:\n",
    "        dict_id_sep[int(row[0])] = row[3:]\n",
    "        \n",
    "list_sep = [row for row in sorted(dict_id_sep.items(), key=lambda x: x[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Filer.writecsv(list_sep, \"./files/edmunds/edmunds_corpus_for_LDA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
