{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\"\"\"\n",
    "igraphを使ったグラフクラスタリング\n",
    "greedyアルゴリズム（louvain法）によってクラスタリングした後\n",
    "サブグラフの中心性指標を図ることで単語の順位付けを行う\n",
    "pagerankによるp(word|topic)の計算\n",
    "purityによるスコアの計算\n",
    "p(word|topic)から凸２次計画問題を解くことで、p(topic)を求める\n",
    "エッジの中でインエッジとアウトエッジの数をノードごとに羅列していく\n",
    "\"\"\"\n",
    "from igraph import *\n",
    "import csv\n",
    "import collections\n",
    "import pickle\n",
    "import numpy as np\n",
    "from openopt import QP\n",
    "import copy\n",
    "import re\n",
    "\n",
    "# csvファイルの読み込み\n",
    "def readcsv(path):\n",
    "    f = open(path, \"rb\")\n",
    "    dataReader = csv.reader(f)\n",
    "    arr = [row for row in dataReader]\n",
    "    return arr\n",
    "\n",
    "def writecsv(arr, path):\n",
    "    f = open(path, \"ab\")\n",
    "    dataWriter = csv.writer(f)\n",
    "    dataWriter.writerows(arr)\n",
    "    f.close()\n",
    "\n",
    "def readdump(path):\n",
    "    f = open(path, \"r\")\n",
    "    arr = pickle.load(f)\n",
    "    f.close()\n",
    "    return arr\n",
    "\n",
    "# 有向エッジリストを入力して、重み付き無向ネットワークを出力する\n",
    "def cal_edgelist_to_network(list_edge):\n",
    "    # 有向エッジリストを無向エッジリストに変換する\n",
    "    list_edge = [tuple(sorted(row)) for row in list_edge]\n",
    "    # ノードリスト\n",
    "    list_vertices = list(set([word for row in list_edge for word in row]))\n",
    "    # エッジリストとそのweightを作成\n",
    "    tuple_edge, tuple_weight = zip(*collections.Counter(list_edge).items())\n",
    "    return {\"vertex\": list_vertices, \"edge\": list(tuple_edge), \"weight\": list(tuple_weight)}\n",
    "    \n",
    "    \n",
    "# クラスタリング済みのネットワークを元にサブグラフのリストを作成\n",
    "# vertexには全てのvertexを代入する（PageRankを計算するため）\n",
    "def cal_cluster_to_network(dict_network):\n",
    "    if dict_network.has_key(\"cluster\") == False:\n",
    "        print \"クラスタリングができていません\"\n",
    "    \n",
    "    # クラスタごとにwordをまとめる\n",
    "    dict_cluster = collections.defaultdict(list)\n",
    "    for word, cluster in zip(dict_network[\"vertex\"], dict_network[\"cluster\"]):\n",
    "        pattern = \"_[0-9]+\"\n",
    "        word1 = re.sub(pattern, \"\", word)\n",
    "        dict_cluster[cluster].append(word1)\n",
    "\n",
    "    # リストに変換\n",
    "    list_cluster_vertex = [row[1] for row in dict_cluster.items()]\n",
    "    \n",
    "    # 同様にエッジとウェイトのリストも作成する\n",
    "    list_cluster_edge = []\n",
    "    list_cluster_weight = []\n",
    "    for cluster_vertex in list_cluster_vertex:\n",
    "        list_cluster_edge_one = []\n",
    "        list_cluster_weight_one = []\n",
    "        # エッジリストの中に、一つでもノードが含まれていれば、そのクラスのノードに含める\n",
    "        for row, weight in zip(dict_network[\"old_edge\"], dict_network[\"old_weight\"]):\n",
    "            # and と or を切り替えることによって性能の比較\n",
    "            if row[0] in cluster_vertex or row[1] in cluster_vertex:\n",
    "                list_cluster_edge_one.append(row)\n",
    "                list_cluster_weight_one.append(weight)\n",
    "        list_cluster_edge.append(list_cluster_edge_one)\n",
    "        list_cluster_weight.append(list_cluster_weight_one)\n",
    "    \n",
    "    # まとめる\n",
    "    list_dict_network = [{\"vertex\": dict_network[\"old_vertex\"],\n",
    "                          \"edge\": cluster_edge,\n",
    "                          \"weight\": cluster_weight}\n",
    "                         for cluster_edge, cluster_weight\n",
    "                         in zip(list_cluster_edge, list_cluster_weight)]\n",
    "    \n",
    "    return list_dict_network\n",
    "\n",
    "# f_measureを計算する\n",
    "def cal_f_measure(list_predict_measure):\n",
    "    # 生成したクラスタ内のカウント\n",
    "    dict_predict_cluster = collections.defaultdict(list)\n",
    "    for row in list_predict_measure:\n",
    "        dict_predict_cluster[row[0]].append(row[1])\n",
    "        \n",
    "    # もとあるクラス内のカウント\n",
    "    dict_measure_cluster = collections.defaultdict(list)\n",
    "    for row in list_predict_measure:\n",
    "        dict_measure_cluster[row[1]].append(row[0])\n",
    "    \n",
    "    # local_purityの計算\n",
    "    list_purity = []\n",
    "    for row in dict_predict_cluster.items():\n",
    "        major_class = sorted(collections.Counter(row[1]).items(), key=lambda x: x[1], reverse=True)[0][1]\n",
    "        class_num = len(row[1])\n",
    "        list_purity.append([major_class, class_num])\n",
    "    purity = float(np.sum(zip(*list_purity)[0])) / np.sum(zip(*list_purity)[1])\n",
    "    print \"Purity: \", purity\n",
    "    \n",
    "    # inverse_purityの計算\n",
    "    list_inverse_purity = []\n",
    "    for row in dict_measure_cluster.items():\n",
    "        major_class = sorted(collections.Counter(row[1]).items(), key=lambda x: x[1], reverse=True)[0][1]\n",
    "        class_num = len(row[1])\n",
    "        list_inverse_purity.append([major_class, class_num])\n",
    "    inverse_purity = float(np.sum(zip(*list_inverse_purity)[0])) / np.sum(zip(*list_inverse_purity)[1])\n",
    "    print \"Inverse Purity: \", inverse_purity\n",
    "    \n",
    "    print \"F-value: \", 2 / (1 / purity + 1 / inverse_purity)\n",
    "    \n",
    "# 凸２次計画問題を解いてp(topic)を求めるための関数\n",
    "def cal_prob_topic(dict_network_master, list_dict_network_sub):\n",
    "    prob_master = np.array([row[1] for row in sorted(zip(dict_network_master[\"old_vertex\"], dict_network_master[\"page_rank\"]), key=lambda x: x[0])])\n",
    "    \n",
    "    for i, dict_network_sub in enumerate(list_dict_network_sub):\n",
    "        if i == 0:\n",
    "            prob_sub = np.array([row[1] for row in sorted(zip(dict_network_sub[\"vertex\"], dict_network_sub[\"page_rank\"]), key=lambda x: x[0])])\n",
    "        else:\n",
    "            list_tmp = np.array([row[1] for row in sorted(zip(dict_network_sub[\"vertex\"], dict_network_sub[\"page_rank\"]), key=lambda x: x[0])])\n",
    "            prob_sub = np.vstack((prob_sub, list_tmp))\n",
    "    \n",
    "    H = 2 * prob_sub.dot(prob_sub.T)\n",
    "    f = -2 * prob_master.dot(prob_sub.T)\n",
    "    Aeq = np.ones(len(list_dict_network_sub))\n",
    "    beq = 1\n",
    "    lb = np.zeros(len(list_dict_network_sub))\n",
    "    \n",
    "    p = QP(H, f, Aeq=Aeq, beq=beq, lb=lb)\n",
    "    r = p.solve(\"cvxopt_qp\")\n",
    "    k_opt = r.xf\n",
    "    return k_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# クラスタリング後に、ノードごとにどのクラスタにエッジを持っているのか計算\n",
    "def cal_cluster_to_edge(dict_network, low_fleq=50, low_rate=0.8):\n",
    "    if dict_network.has_key(\"cluster\") == False:\n",
    "        print \"クラスタリングができていません\"\n",
    "    \n",
    "    # クラスタごとにwordをまとめる\n",
    "    dict_cluster = collections.defaultdict(list)\n",
    "    for word, cluster in zip(dict_network[\"vertex\"], dict_network[\"cluster\"]):\n",
    "        dict_cluster[cluster].append(word)\n",
    "        \n",
    "    # wordをclusterに変換するための辞書を作成する\n",
    "    dict_word_to_cluster = {}\n",
    "    for word, cluster in zip(dict_network[\"vertex\"], dict_network[\"cluster\"]):\n",
    "        dict_word_to_cluster[word] = cluster\n",
    "        \n",
    "    # wordをidに変換するための辞書を作成する\n",
    "    dict_word_to_id = {}\n",
    "    for i, word in enumerate(dict_network[\"vertex\"]):\n",
    "        dict_word_to_id[word] = i\n",
    "    \n",
    "    # id_to_idのマトリックス\n",
    "    matrix_id_to_cluster = np.zeros((len(dict_word_to_id), len(dict_cluster)))\n",
    "    for row, weight in zip(dict_network[\"edge\"], dict_network[\"weight\"]):\n",
    "        matrix_id_to_cluster[dict_word_to_id[row[0]]][dict_word_to_cluster[row[1]]] += weight\n",
    "        matrix_id_to_cluster[dict_word_to_id[row[1]]][dict_word_to_cluster[row[0]]] += weight\n",
    "    \n",
    "    # 指定したハイパーパラメータよりも高い値を記録した単語を所属クラスタとともに辞書に登録する\n",
    "    dict_word_to_list_cluster = {}\n",
    "    for cluster, word, row in zip(dict_network[\"cluster\"], dict_network[\"vertex\"], matrix_id_to_cluster):\n",
    "        top_num = max(row)\n",
    "        if np.sum(row) >= low_fleq and len(np.where( row/top_num >= low_rate)[0])>=2:\n",
    "            print word\n",
    "            dict_word_to_list_cluster[word] = np.where(row/top_num >= low_rate)[0]\n",
    "    \n",
    "    \n",
    "    # 新しく分裂するノードクラスターを元のクラスターに記録\n",
    "    for word, row in dict_word_to_list_cluster.items():\n",
    "        for num in row:\n",
    "            # dict_word_to_cluster[word+\"_\"+str(num)] = num\n",
    "            dict_word_to_cluster[word+\"_\"+str(num)] = dict_word_to_cluster[word]\n",
    "    \n",
    "    dict_network[\"old_edge\"] = copy.deepcopy(dict_network[\"edge\"])\n",
    "    dict_network[\"old_weight\"] = copy.deepcopy(dict_network[\"weight\"])\n",
    "    dict_network[\"old_vertex\"] = copy.deepcopy(dict_network[\"vertex\"])\n",
    "    # ここの計算が絶対に間違ってる => diffsplitで確認したが大丈夫そう・・・\n",
    "    for word in dict_word_to_list_cluster.keys():\n",
    "        list_edge_new = []\n",
    "        list_weight_new = []\n",
    "        for row, weight in zip(dict_network[\"edge\"], dict_network[\"weight\"]):\n",
    "            if row[0] == word:\n",
    "                if dict_word_to_cluster[row[1]] in dict_word_to_list_cluster[word]:\n",
    "                    list_edge_new.append([row[0]+\"_\"+str(dict_word_to_cluster[row[1]]), row[1]])\n",
    "                    list_weight_new.append(weight)\n",
    "                else:\n",
    "                    for num in dict_word_to_list_cluster[word]:\n",
    "                        list_edge_new.append([row[0]+\"_\"+str(num), row[1]])\n",
    "                        list_weight_new.append(float(weight)/len(dict_word_to_list_cluster[word]))\n",
    "            elif row[1] == word:\n",
    "                if dict_word_to_cluster[row[0]] in dict_word_to_list_cluster[word]:\n",
    "                    list_edge_new.append([row[0], row[1]+\"_\"+str(dict_word_to_cluster[row[0]])])\n",
    "                    list_weight_new.append(weight)\n",
    "                else:\n",
    "                    for num in dict_word_to_list_cluster[word]:\n",
    "                        list_edge_new.append([row[0], row[1]+\"_\"+str(num)])\n",
    "                        list_weight_new.append(float(weight)/len(dict_word_to_list_cluster[word]))\n",
    "            else:\n",
    "                list_edge_new.append([row[0], row[1]])\n",
    "                list_weight_new.append(weight)\n",
    "        else:\n",
    "            dict_network[\"edge\"] = copy.deepcopy(list_edge_new)\n",
    "            dict_network[\"weight\"] = copy.deepcopy(list_weight_new)\n",
    "            list_vertices = list(set([word for row in dict_network[\"edge\"] for word in row]))\n",
    "            dict_network[\"vertex\"] = list_vertices\n",
    "    \n",
    "    return dict_network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###メイン部分\n",
    "1. 有向エッジリストから無向重み付きエッジリストを作成\n",
    "2. louvain法によるクラスタリング\n",
    "3. クラスタごとにpagerankを計算し、p(word|topic)とする\n",
    "4. クラスタごとにp(word|topic)を出力する辞書を作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "方々\n",
      "非常\n",
      "いい\n",
      "充実\n",
      "大変\n",
      "見学\n",
      "9888\n",
      "9888\n",
      "クラスタ数:  9\n",
      "\n",
      "------------------------- OpenOpt 0.5625 -------------------------\n",
      "problem: unnamed   type: QP\n",
      "solver: cvxopt_qp\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.6718e-03 -1.0026e+00  1e+00  3e-16  3e+00\n",
      " 1: -1.6730e-03 -1.2561e-02  1e-02  1e-16  4e-02\n",
      " 2: -1.7479e-03 -2.5381e-03  8e-04  2e-16  3e-03\n",
      " 3: -1.9108e-03 -2.0380e-03  1e-04  1e-16  1e-18\n",
      " 4: -1.9299e-03 -1.9412e-03  1e-05  4e-17  2e-18\n",
      " 5: -1.9310e-03 -1.9316e-03  6e-07  7e-17  1e-18\n",
      " 6: -1.9310e-03 -1.9310e-03  9e-09  1e-16  1e-18\n",
      "Optimal solution found.\n",
      "istop: 1000 (optimal)\n",
      "Solver:   Time Elapsed = 0.0 \tCPU Time Elapsed = 0.0\n",
      "objFuncValue: -0.0019310228 (feasible, MaxResidual = 0)\n"
     ]
    }
   ],
   "source": [
    "# エッジリストの読み込み\n",
    "list_edge = readcsv(\"./files/kaigo_honne/list_edgelist20160127.csv\")\n",
    "# 元のネットワークを作成する（無向）\n",
    "dict_network_master = cal_edgelist_to_network(list_edge)\n",
    "# g = Graph(directed=True)\n",
    "g_master = Graph()\n",
    "g_master.add_vertices(dict_network_master[\"vertex\"])\n",
    "g_master.add_edges(dict_network_master[\"edge\"])\n",
    "# louvain法によるクラスタリング、vertexと同じ長さのクラスタ番号が書かれたリストがreturn\n",
    "dict_network_master[\"cluster\"] = g_master.community_fastgreedy(weights=dict_network_master[\"weight\"]).as_clustering().membership\n",
    "# 元のネットワークのpagerankを求める\n",
    "dict_network_master[\"page_rank\"] = g_master.pagerank(directed=False, weights=dict_network_master[\"weight\"])\n",
    "# クラスタリングの結果をもとに、どのノードから何本のエッジが出ているか計算する\n",
    "dict_network_master = cal_cluster_to_edge(dict_network_master, low_fleq=100, low_rate=0.7)\n",
    "\"\"\"\n",
    "list_tmp = []\n",
    "for row, weight in zip(dict_network_master[\"edge\"], dict_network_master[\"weight\"]):\n",
    "    list_tmp.append([row[0], row[1], weight])\n",
    "list_tmp_old = []\n",
    "for row, weight in zip(dict_network_master[\"old_edge\"], dict_network_master[\"old_weight\"]):\n",
    "    list_tmp_old.append([row[0], row[1], weight])\n",
    "list_tmp = sorted(list_tmp, key=lambda x:x[0])\n",
    "list_tmp_old = sorted(list_tmp_old, key=lambda x:x[0])\n",
    "for row in list_tmp:\n",
    "    print row[0], row[1], row[2]\n",
    "print \"=============\"\n",
    "for row in list_tmp_old:\n",
    "    print row[0], row[1], row[2]\n",
    "\"\"\"\n",
    "print len(dict_network_master[\"weight\"])\n",
    "print len(dict_network_master[\"edge\"])\n",
    "g_master = Graph()\n",
    "g_master.add_vertices(dict_network_master[\"vertex\"])\n",
    "g_master.add_edges(dict_network_master[\"edge\"])\n",
    "dict_network_master[\"cluster\"] = g_master.community_fastgreedy(weights=dict_network_master[\"weight\"]).as_clustering().membership\n",
    "# クラスタ結果をもとにサブグラフのリストを作成\n",
    "list_dict_network_sub = cal_cluster_to_network(dict_network_master)\n",
    "# サブクラスタごとに中心性の計算\n",
    "for i, dict_network_sub in enumerate(list_dict_network_sub):\n",
    "    g_sub = Graph()\n",
    "    g_sub.add_vertices(dict_network_sub[\"vertex\"])\n",
    "    g_sub.add_edges(dict_network_sub[\"edge\"])\n",
    "    list_dict_network_sub[i][\"page_rank\"] = g_sub.pagerank(directed=False, weights=dict_network_sub[\"weight\"])\n",
    "print \"クラスタ数: \", len(list_dict_network_sub)\n",
    "\n",
    "# トピックごとにwordを入力したらp(word|topic)が出るような辞書を作成\n",
    "list_dict_prob = []\n",
    "for i in range(len(list_dict_network_sub)):\n",
    "    list_word_page = sorted(zip(list_dict_network_sub[i][\"vertex\"], list_dict_network_sub[i][\"page_rank\"]), key=lambda x: x[1], reverse=True)\n",
    "    list_dict_prob.append({row[0]: row[1] for row in list_word_page})\n",
    "    \n",
    "# 凸２次計画問題を解いて、p(topic)を求める\n",
    "list_prob_topic = cal_prob_topic(dict_network_master, list_dict_network_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ライフ 0.0264298860773\n",
      "ロング 0.0217871750132\n",
      "芦屋 0.0027399213852\n",
      "成城 0.0027399213852\n",
      "女性 0.0027399213852\n",
      "低価格 0.0027399213852\n",
      "ケア 0.0027399213852\n",
      "有料老人ホーム 0.0027399213852\n",
      "明るい 0.0027399213852\n",
      "プラン 0.00271971433085\n"
     ]
    }
   ],
   "source": [
    "num = 7\n",
    "list_tmp = sorted(list_dict_prob[num].items(), key=lambda x: x[1], reverse=True)\n",
    "for i in range(10):\n",
    "    print list_tmp[i][0], list_tmp[i][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定量評価部分\n",
    "1. 形態素解析済みセンテンスを読み込み、確率を計算し、どのクラスに属するか計算\n",
    "2. 予測クラスと実際クラスのリストを作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "エラーデータ数:  68\n"
     ]
    }
   ],
   "source": [
    "list_sep_words = readdump(\"./files/kaigo_honne/list_sep_words_label.dump\")\n",
    "list_words= readcsv(\"./files/kaigo_honne/list_sentence_user_label.csv\")\n",
    "# 確率が最大になるクラスを予想する\n",
    "# 実質ラベルがintじゃない場合は、エラーとして、記録しない\n",
    "list_predict_measure = []\n",
    "list_words_rev = []\n",
    "error_count = 0\n",
    "for row, row1 in zip(list_sep_words, list_words):\n",
    "    try:\n",
    "        class_tmp = 0\n",
    "        prob_tmp = 0\n",
    "        predict_class = []\n",
    "        for num, dict_prob in enumerate(list_dict_prob):\n",
    "            prob_tmp_tmp = 1\n",
    "            for word in row[0]:\n",
    "                prob_tmp_tmp *= float(dict_prob[word])\n",
    "            prob_tmp_tmp *= list_prob_topic[num]\n",
    "            if prob_tmp_tmp > prob_tmp:\n",
    "                class_tmp = num\n",
    "                prob_tmp = prob_tmp_tmp\n",
    "        list_predict_measure.append([class_tmp, row[1]])\n",
    "        list_words_rev.append(row1)\n",
    "    except:\n",
    "        error_count += 1\n",
    "print \"エラーデータ数: \", error_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###計算結果の表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 100, 0.7, or、切り捨て、割りあてるクラスタを変更,で計算した場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity:  0.495293045855\n",
      "Inverse Purity:  0.650470695415\n",
      "F-value:  0.562373551138\n"
     ]
    }
   ],
   "source": [
    "cal_f_measure(list_predict_measure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 100, 0.7, or、少数、割りあてるクラスタを変更,で計算した場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity:  0.494989371394\n",
      "Inverse Purity:  0.648041299727\n",
      "F-value:  0.561268500826\n"
     ]
    }
   ],
   "source": [
    "cal_f_measure(list_predict_measure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 50, 0.7, or、切り捨て、割りあてるクラスタを変更,で計算した場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity:  0.488004858791\n",
      "Inverse Purity:  0.646219252961\n",
      "F-value:  0.556077290232\n"
     ]
    }
   ],
   "source": [
    "cal_f_measure(list_predict_measure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 100, 0.6, or、切り捨て、割りあてるクラスタを変更,で計算した場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity:  0.493167324628\n",
      "Inverse Purity:  0.644093531734\n",
      "F-value:  0.558615698551\n"
     ]
    }
   ],
   "source": [
    "cal_f_measure(list_predict_measure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 100, 0.7, or、切り捨てで計算した場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity:  0.486486486486\n",
      "Inverse Purity:  0.649559672032\n",
      "F-value:  0.556318949262\n"
     ]
    }
   ],
   "source": [
    "cal_f_measure(list_predict_measure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 100, 0.9, or, 切り捨てで計算した場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity:  0.487093835408\n",
      "Inverse Purity:  0.623443668387\n",
      "F-value:  0.546898356081\n"
     ]
    }
   ],
   "source": [
    "cal_f_measure(list_predict_measure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 50, 0.8, or, 切り捨てで計算した結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity:  0.494078348011\n",
      "Inverse Purity:  0.638931065897\n",
      "F-value:  0.557245159054\n"
     ]
    }
   ],
   "source": [
    "cal_f_measure(list_predict_measure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 50, 0.7, or, 切り捨てで計算した結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity:  0.486486486486\n",
      "Inverse Purity:  0.649559672032\n",
      "F-value:  0.556318949262\n"
     ]
    }
   ],
   "source": [
    "cal_f_measure(list_predict_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity:  0.492256301245\n",
      "Inverse Purity:  0.639234740358\n",
      "F-value:  0.556199417134\n"
     ]
    }
   ],
   "source": [
    "cal_f_measure(list_predict_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
